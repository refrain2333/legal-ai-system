#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºçš„APIè·¯ç”± - åŒ…å«å¯åŠ¨çŠ¶æ€ç›‘æ§
éµå¾ªåˆ†å±‚æ¶æ„åŸåˆ™ï¼Œä»…è°ƒç”¨æœåŠ¡å±‚
"""

import logging
import asyncio
from fastapi import APIRouter, HTTPException, Depends, WebSocket, WebSocketDisconnect
from typing import List, Dict, Any
from .models import SearchRequest, SearchResponse, StatusResponse, SearchResult
from ..services.search_service import SearchService
from ..infrastructure.repositories import get_legal_document_repository
from ..infrastructure.startup import get_startup_manager
from ..infrastructure.llm.llm_client import LLMClient
from ..config.settings import settings

logger = logging.getLogger(__name__)

# åˆ›å»ºè·¯ç”±å™¨
router = APIRouter()

# åˆ›å»ºå…¨å±€LLMå®¢æˆ·ç«¯å®ä¾‹ï¼ˆå•ä¾‹ï¼‰
_llm_client_instance = None

def get_llm_client() -> LLMClient:
    """è·å–LLMå®¢æˆ·ç«¯å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _llm_client_instance
    if _llm_client_instance is None:
        _llm_client_instance = LLMClient(settings)
        logger.info("åˆ›å»ºLLMå®¢æˆ·ç«¯å•ä¾‹å®ä¾‹")
    return _llm_client_instance

def get_search_service() -> SearchService:
    """ä¾èµ–æ³¨å…¥ï¼šä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºæ–°çš„æœç´¢æœåŠ¡å®ä¾‹"""
    # è·å–å…±äº«çš„åªè¯»èµ„æº
    repository = get_legal_document_repository()
    llm_client = get_llm_client()
    # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºæ–°çš„SearchServiceå®ä¾‹ï¼Œé¿å…çŠ¶æ€æ±¡æŸ“
    return SearchService(repository, llm_client, debug_mode=False)

def get_debug_search_service() -> SearchService:
    """ä¾èµ–æ³¨å…¥ï¼šä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºæ–°çš„è°ƒè¯•æ¨¡å¼æœç´¢æœåŠ¡å®ä¾‹"""
    # è·å–å…±äº«çš„åªè¯»èµ„æº
    repository = get_legal_document_repository()
    llm_client = get_llm_client()
    # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºæ–°çš„SearchServiceå®ä¾‹ï¼Œé¿å…çŠ¶æ€æ±¡æŸ“
    return SearchService(repository, llm_client, debug_mode=True)

# WebSocketè¿æ¥ç®¡ç†å™¨
class WebSocketManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        try:
            await websocket.accept()
            self.active_connections.append(websocket)
            logger.info(f"WebSocketè¿æ¥å·²å»ºç«‹ï¼Œå½“å‰è¿æ¥æ•°: {len(self.active_connections)}")
        except Exception as e:
            logger.error(f"WebSocketè¿æ¥å¤±è´¥: {e}")

    async def disconnect(self, websocket: WebSocket):
        try:
            if websocket in self.active_connections:
                self.active_connections.remove(websocket)
                logger.info(f"WebSocketè¿æ¥å·²æ–­å¼€ï¼Œå½“å‰è¿æ¥æ•°: {len(self.active_connections)}")
        except Exception as e:
            logger.error(f"WebSocketæ–­å¼€è¿æ¥é”™è¯¯: {e}")

    async def broadcast(self, message: Dict[str, Any]):
        if not self.active_connections:
            logger.debug("æ²¡æœ‰æ´»è·ƒçš„WebSocketè¿æ¥ï¼Œè·³è¿‡å¹¿æ’­")
            return

        disconnected = []
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except Exception as e:
                logger.warning(f"WebSocketå‘é€æ¶ˆæ¯å¤±è´¥: {e}")
                disconnected.append(connection)

        # æ¸…ç†å¤±æ•ˆè¿æ¥
        for conn in disconnected:
            await self.disconnect(conn)

websocket_manager = WebSocketManager()

@router.post("/search", response_model=SearchResponse)
async def search(request: SearchRequest, search_service: SearchService = Depends(get_search_service)):
    """æœç´¢æ¥å£ - æ–°æ ¼å¼ï¼š5æ¡æ³•æ¡ + 5æ¡æ¡ˆä¾‹"""
    try:
        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å‡†å¤‡å°±ç»ª
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail={
                    "error": "ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•",
                    "loading_info": startup_manager.get_summary()
                }
            )
        
        # è°ƒç”¨æœåŠ¡å±‚æ‰§è¡Œä¸šåŠ¡é€»è¾‘
        service_result = await search_service.search_documents_mixed(
            query_text=request.query,
            articles_count=5,
            cases_count=5
        )
        
        # æ£€æŸ¥æœåŠ¡å±‚è¿”å›çš„ç»“æœ
        if not service_result.get('success', False):
            raise HTTPException(
                status_code=400, 
                detail=service_result.get('error', 'æœç´¢å¤±è´¥')
            )
        
        # è½¬æ¢ä¸ºAPIå“åº”æ ¼å¼ - å…ˆæ³•æ¡åæ¡ˆä¾‹
        api_results = []
        
        # æ·»åŠ æ³•æ¡ç»“æœ
        for item in service_result.get('articles', []):
            result = SearchResult(
                id=item.get('id', ''),
                title=item.get('title', ''),
                content=item.get('content', ''),
                similarity=item.get('similarity', 0.0),
                type=item.get('type', 'article'),
                # æ³•æ¡ç‰¹æœ‰å­—æ®µ
                article_number=item.get('article_number'),
                chapter=item.get('chapter'),
                # æ¡ˆä¾‹å­—æ®µè®¾ä¸ºNone
                case_id=None, criminals=None, accusations=None, relevant_articles=None,
                punish_of_money=None, death_penalty=None, life_imprisonment=None, imprisonment_months=None
            )
            api_results.append(result)
        
        # æ·»åŠ æ¡ˆä¾‹ç»“æœ
        for item in service_result.get('cases', []):
            result = SearchResult(
                id=item.get('id', ''),
                title=item.get('title', ''),
                content=item.get('content', ''),
                similarity=item.get('similarity', 0.0),
                type=item.get('type', 'case'),
                # æ¡ˆä¾‹ç‰¹æœ‰å­—æ®µ
                case_id=item.get('case_id'),
                criminals=item.get('criminals'),
                accusations=item.get('accusations'),
                relevant_articles=item.get('relevant_articles'),
                punish_of_money=item.get('punish_of_money'),
                death_penalty=item.get('death_penalty'),
                life_imprisonment=item.get('life_imprisonment'),
                imprisonment_months=item.get('imprisonment_months'),
                # æ³•æ¡å­—æ®µè®¾ä¸ºNone
                article_number=None, chapter=None
            )
            api_results.append(result)
        
        return SearchResponse(
            success=True,
            results=api_results,
            total=len(api_results),
            query=request.query
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœç´¢æœåŠ¡é”™è¯¯: {str(e)}")

# ==================== è°ƒè¯•æœç´¢ API ====================

@router.post("/search/debug")
async def search_debug(
    request: SearchRequest,
    search_service: SearchService = Depends(get_debug_search_service)
) -> Dict[str, Any]:
    """AIé©±åŠ¨çš„æ™ºèƒ½æœç´¢ - å®Œæ•´è°ƒè¯•æ¨¡å¼"""
    try:
        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å‡†å¤‡å°±ç»ª
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail={
                    "error": "ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•",
                    "loading_info": startup_manager.get_summary()
                }
            )

        # ğŸš€ å…³é”®ä¿®å¤ï¼šåœ¨è°ƒç”¨æœç´¢å‰å°±è®¾ç½®WebSocketç®¡ç†å™¨
        search_service.set_websocket_manager(websocket_manager)

        # è°ƒç”¨æ™ºèƒ½æœç´¢è°ƒè¯•ç‰ˆæœ¬
        debug_result = await search_service.search_documents_intelligent_debug(
            query_text=request.query,
            debug=True
        )

        # å‘WebSocketå¹¿æ’­å®æ—¶æ›´æ–°
        if debug_result.get('success') and debug_result.get('trace'):
            await websocket_manager.broadcast({
                "type": "search_completed",
                "request_id": debug_result.get('request_id'),
                "query": request.query,
                "trace_summary": {
                    "total_duration_ms": debug_result['trace'].get('total_duration_ms', 0),
                    "processing_mode": debug_result['trace'].get('processing_mode'),
                    "stages_completed": debug_result['trace']['summary'].get('stages_completed', 0),
                    "successful_modules": debug_result['trace']['summary'].get('successful_modules', 0)
                }
            })

        return debug_result

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è°ƒè¯•æœç´¢æœåŠ¡é”™è¯¯: {str(e)}")

@router.get("/search/trace/{request_id}")
async def get_search_trace(request_id: str) -> Dict[str, Any]:
    """è·å–æŒ‡å®šæœç´¢çš„å®Œæ•´traceè®°å½•"""
    try:
        # è¿™é‡Œåº”è¯¥ä»ç¼“å­˜æˆ–æ•°æ®åº“ä¸­è·å–traceè®°å½•
        # å½“å‰ç®€åŒ–å®ç°ï¼Œè¿”å›æç¤ºä¿¡æ¯
        return {
            "success": False,
            "message": "Traceå­˜å‚¨åŠŸèƒ½å¾…å®ç°ï¼Œè¯·ä½¿ç”¨å®æ—¶è°ƒè¯•æœç´¢",
            "request_id": request_id,
            "suggestion": "ä½¿ç”¨ POST /search/debug è¿›è¡Œå®æ—¶è°ƒè¯•æœç´¢"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æœç´¢traceå¤±è´¥: {str(e)}")

@router.get("/debug/modules/status")
async def get_modules_status(
    search_service: SearchService = Depends(get_search_service)
) -> Dict[str, Any]:
    """è·å–æ‰€æœ‰æœç´¢æ¨¡å—çš„å½“å‰çŠ¶æ€"""
    try:
        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å‡†å¤‡å°±ç»ª
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail="ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•"
            )

        # è·å–å„æ¨¡å—çŠ¶æ€
        modules_status = []

        # åŸºç¡€æœç´¢çŠ¶æ€
        basic_status = search_service.get_system_status()
        modules_status.append({
            "module_name": "basic_semantic_search",
            "status": "ok" if basic_status.get('ready') else "error",
            "reason": "åŸºç¡€è¯­ä¹‰æœç´¢å¼•æ“çŠ¶æ€",
            "last_check": "2024-01-01T00:00:00Z",
            "performance_stats": {
                "avg_response_time_ms": 150,
                "total_documents": basic_status.get('total_documents', 0)
            }
        })

        # LLMå¢å¼ºæœç´¢çŠ¶æ€
        llm_status = search_service.get_llm_enhancement_status()
        modules_status.append({
            "module_name": "llm_enhanced_search",
            "status": "error" if not llm_status.get('llm_enhancement_available') else "warning",
            "reason": "LLMå¢å¼ºæœç´¢å½“å‰æœ‰ä»£ç bug" if not llm_status.get('llm_enhancement_available') else "åŠŸèƒ½å¯ç”¨ä½†éœ€è¦éªŒè¯",
            "last_check": "2024-01-01T00:00:00Z",
            "performance_stats": {
                "supported_methods": llm_status.get('supported_methods', [])
            }
        })

        # çŸ¥è¯†å›¾è°±å¢å¼ºæœç´¢çŠ¶æ€
        kg_status = search_service.get_kg_enhanced_status()
        modules_status.append({
            "module_name": "knowledge_graph_search",
            "status": "warning" if kg_status.get('kg_enhancement_available') else "error",
            "reason": "çŸ¥è¯†å›¾è°±æœç´¢å¼•æ“æœªåˆå§‹åŒ–" if not kg_status.get('kg_enhancement_available') else "çŸ¥è¯†å›¾è°±åŠŸèƒ½å¯ç”¨",
            "last_check": "2024-01-01T00:00:00Z",
            "performance_stats": {
                "knowledge_graph_stats": kg_status.get('knowledge_graph_stats', {})
            }
        })

        # BM25æ··åˆæœç´¢çŠ¶æ€
        modules_status.append({
            "module_name": "bm25_hybrid_search",
            "status": "ok",
            "reason": "BM25æ··åˆæœç´¢åŠŸèƒ½æ­£å¸¸",
            "last_check": "2024-01-01T00:00:00Z",
            "performance_stats": {
                "fusion_method": "RRF",
                "avg_response_time_ms": 200
            }
        })

        return {
            "success": True,
            "modules_status": modules_status,
            "recent_searches": [],  # å¾…å®ç°
            "performance_metrics": {
                "total_searches_today": 0,
                "avg_response_time": 150.0,
                "success_rate": 0.95,
                "system_uptime": "24h"
            },
            "system_health": "partial" if any(m['status'] == 'error' for m in modules_status) else "good"
        }

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ¨¡å—çŠ¶æ€å¤±è´¥: {str(e)}")

@router.websocket("/debug/realtime")
async def debug_websocket(websocket: WebSocket):
    """WebSocketç«¯ç‚¹ - ç”¨äºå®æ—¶è°ƒè¯•æ•°æ®æ¨é€"""
    logger.info("æ–°çš„WebSocketè¿æ¥è¯·æ±‚")

    await websocket_manager.connect(websocket)

    try:
        # å‘é€æ¬¢è¿æ¶ˆæ¯
        welcome_message = {
            "type": "connected",
            "message": "è°ƒè¯•WebSocketè¿æ¥å·²å»ºç«‹",
            "timestamp": "2024-01-01T00:00:00Z",
            "connection_id": len(websocket_manager.active_connections)
        }
        await websocket.send_json(welcome_message)
        logger.info(f"å·²å‘é€æ¬¢è¿æ¶ˆæ¯: {welcome_message}")

        # ä¿æŒè¿æ¥æ´»è·ƒ
        while True:
            try:
                # ç­‰å¾…æ¥è‡ªå®¢æˆ·ç«¯çš„æ¶ˆæ¯
                data = await websocket.receive_json()
                logger.info(f"æ”¶åˆ°WebSocketæ¶ˆæ¯: {data}")

                if data.get("type") == "ping":
                    pong_message = {
                        "type": "pong",
                        "timestamp": "2024-01-01T00:00:00Z"
                    }
                    await websocket.send_json(pong_message)
                    logger.info("å›å¤pongæ¶ˆæ¯")

                elif data.get("type") == "subscribe":
                    subscribe_message = {
                        "type": "subscribed",
                        "subscription": data.get("events", ["all"]),
                        "timestamp": "2024-01-01T00:00:00Z"
                    }
                    await websocket.send_json(subscribe_message)
                    logger.info(f"ç¡®è®¤è®¢é˜…: {subscribe_message}")

            except WebSocketDisconnect:
                logger.info("å®¢æˆ·ç«¯ä¸»åŠ¨æ–­å¼€WebSocketè¿æ¥")
                break
            except Exception as e:
                logger.error(f"WebSocketå¤„ç†æ¶ˆæ¯é”™è¯¯: {e}")
                break

    except WebSocketDisconnect:
        logger.info("WebSocketè¿æ¥æ–­å¼€")
    except Exception as e:
        logger.error(f"WebSocketè¿æ¥é”™è¯¯: {e}")
    finally:
        await websocket_manager.disconnect(websocket)

@router.get("/debug/system/info")
async def get_system_debug_info(
    search_service: SearchService = Depends(get_search_service)
) -> Dict[str, Any]:
    """è·å–ç³»ç»Ÿæ•´ä½“è°ƒè¯•ä¿¡æ¯"""
    try:
        # è·å–æ¨¡å—çŠ¶æ€ï¼ˆå¤ç”¨ä¸Šé¢çš„é€»è¾‘ï¼‰
        modules_response = await get_modules_status(search_service)

        return {
            "success": True,
            "system_info": {
                "version": "1.0.0",
                "environment": "development",
                "python_version": "3.9+",
                "framework": "FastAPI + DDDæ¶æ„"
            },
            "modules_status": modules_response["modules_status"],
            "recent_searches": modules_response["recent_searches"],
            "performance_metrics": modules_response["performance_metrics"],
            "system_health": modules_response["system_health"],
            "debug_capabilities": {
                "trace_collection": True,
                "realtime_websocket": True,
                "module_monitoring": True,
                "performance_tracking": True,
                "error_reporting": True
            }
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç³»ç»Ÿè°ƒè¯•ä¿¡æ¯å¤±è´¥: {str(e)}")

# ==================== æœç´¢å†å²å’Œæ€§èƒ½ API ====================

@router.get("/search/history")
async def get_search_history(
    limit: int = 20,
    offset: int = 0
) -> Dict[str, Any]:
    """è·å–æœç´¢å†å²è®°å½•"""
    try:
        # æ¨¡æ‹Ÿæœç´¢å†å²æ•°æ®
        mock_history = [
            {
                "request_id": "req-001",
                "query": "æ•…æ„ä¼¤å®³ç½ªåˆ¤å‡ å¹´",
                "timestamp": "2024-01-01T10:00:00Z",
                "duration_ms": 150,
                "success": True,
                "result_count": 8,
                "mode": "criminal_law",
                "tags": ["åˆ‘æ³•", "æ•…æ„ä¼¤å®³"]
            },
            {
                "request_id": "req-002",
                "query": "ç›—çªƒç½ªçš„é‡åˆ‘æ ‡å‡†",
                "timestamp": "2024-01-01T10:05:00Z",
                "duration_ms": 200,
                "success": True,
                "result_count": 10,
                "mode": "criminal_law",
                "tags": ["åˆ‘æ³•", "ç›—çªƒ"]
            }
        ]

        return {
            "success": True,
            "history": mock_history[offset:offset+limit],
            "total": len(mock_history),
            "offset": offset,
            "limit": limit,
            "has_more": offset + limit < len(mock_history)
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æœç´¢å†å²å¤±è´¥: {str(e)}")

@router.get("/performance/stats")
async def get_performance_stats() -> Dict[str, Any]:
    """è·å–ç³»ç»Ÿæ€§èƒ½ç»Ÿè®¡"""
    try:
        # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®
        return {
            "success": True,
            "performance_stats": {
                "avgResponseTime": 175.5,
                "successRate": 0.96,
                "modulesStatus": {
                    "basic_semantic": {"status": "ok", "avgTime": 120, "successRate": 0.98},
                    "llm_enhanced": {"status": "error", "avgTime": 0, "successRate": 0.0},
                    "knowledge_graph": {"status": "warning", "avgTime": 180, "successRate": 0.85},
                    "bm25_hybrid": {"status": "ok", "avgTime": 200, "successRate": 0.95}
                },
                "recentQueries": [
                    {
                        "request_id": "req-latest-001",
                        "query": "æœ€è¿‘çš„æŸ¥è¯¢ç¤ºä¾‹",
                        "timestamp": "2024-01-01T12:00:00Z",
                        "duration_ms": 180,
                        "success": True,
                        "result_count": 7,
                        "mode": "criminal_law",
                        "tags": ["æµ‹è¯•"]
                    }
                ]
            },
            "update_time": "2024-01-01T12:00:00Z"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ€§èƒ½ç»Ÿè®¡å¤±è´¥: {str(e)}")

@router.get("/search/cases/more")
async def load_more_cases(query: str, offset: int = 0, limit: int = 5, 
                         search_service: SearchService = Depends(get_search_service)):
    """åˆ†é¡µåŠ è½½æ›´å¤šæ¡ˆä¾‹"""
    try:
        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å‡†å¤‡å°±ç»ª
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail="ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•"
            )
        
        # è°ƒç”¨æœåŠ¡å±‚åŠ è½½æ›´å¤šæ¡ˆä¾‹
        service_result = await search_service.load_more_cases(query, offset, limit)
        
        if not service_result.get('success', False):
            raise HTTPException(
                status_code=400,
                detail=service_result.get('error', 'åŠ è½½å¤±è´¥')
            )
        
        # è½¬æ¢ä¸ºAPIå“åº”æ ¼å¼
        api_cases = []
        for item in service_result.get('cases', []):
            result = SearchResult(
                id=item.get('id', ''),
                title=item.get('title', ''),
                content=item.get('content', ''),
                similarity=item.get('similarity', 0.0),
                type=item.get('type', 'case'),
                case_id=item.get('case_id'),
                criminals=item.get('criminals'),
                accusations=item.get('accusations'),
                relevant_articles=item.get('relevant_articles'),
                punish_of_money=item.get('punish_of_money'),
                death_penalty=item.get('death_penalty'),
                life_imprisonment=item.get('life_imprisonment'),
                imprisonment_months=item.get('imprisonment_months'),
                article_number=None, chapter=None
            )
            api_cases.append(result)
        
        return {
            "success": True,
            "cases": api_cases,
            "offset": service_result.get('offset', offset),
            "limit": service_result.get('limit', limit),
            "returned_count": service_result.get('returned_count', len(api_cases)),
            "has_more": service_result.get('has_more', False),
            "query": query
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åŠ è½½æ›´å¤šæ¡ˆä¾‹é”™è¯¯: {str(e)}")

@router.get("/status", response_model=StatusResponse)
async def get_status(search_service: SearchService = Depends(get_search_service)):
    """è·å–ç³»ç»ŸçŠ¶æ€ - å¢å¼ºç‰ˆåŒ…å«å¯åŠ¨ä¿¡æ¯"""
    try:
        # è·å–å¯åŠ¨çŠ¶æ€
        startup_manager = get_startup_manager()
        startup_summary = startup_manager.get_summary()
        
        # è°ƒç”¨æœåŠ¡å±‚è·å–æœç´¢ç³»ç»ŸçŠ¶æ€ä¿¡æ¯
        search_status = search_service.get_system_status()
        
        return StatusResponse(
            status=search_status.get('status', 'unknown'),
            ready=startup_manager.is_ready() and search_status.get('ready', False),
            total_documents=search_status.get('total_documents', 0),
            startup_info=startup_summary
        )
        
    except Exception as e:
        # é™çº§å¤„ç†ï¼šè¿”å›é”™è¯¯çŠ¶æ€è€Œä¸æŠ›å‡ºå¼‚å¸¸
        return StatusResponse(
            status="error",
            ready=False,
            total_documents=0,
            startup_info={
                "is_loading": False,
                "overall_progress": 0.0,
                "error": str(e)
            }
        )

# æ–°å¢ï¼šå¯åŠ¨çŠ¶æ€ä¸“ç”¨API
@router.get("/startup/status")
async def get_startup_status():
    """è·å–è¯¦ç»†çš„å¯åŠ¨çŠ¶æ€ä¿¡æ¯"""
    try:
        startup_manager = get_startup_manager()
        current_status = startup_manager.get_current_status()
        
        # æ„å»ºè¯¦ç»†çš„çŠ¶æ€å“åº”
        steps_info = []
        for step_id, step in current_status.steps.items():
            steps_info.append({
                "id": step.id,
                "name": step.name,
                "description": step.description,
                "status": step.status.value,
                "progress": step.progress,
                "duration": step.duration,
                "error_message": step.error_message,
                "details": step.details
            })
        
        return {
            "success": True,
            "system_status": {
                "is_loading": current_status.is_loading,
                "overall_progress": current_status.overall_progress,
                "current_step": current_status.current_step,
                "total_duration": current_status.total_duration,
                "completed_steps": current_status.completed_steps,
                "success_steps": current_status.success_steps,
                "failed_steps": current_status.failed_steps,
                "is_ready": startup_manager.is_ready()
            },
            "steps": steps_info,
            "summary": startup_manager.get_summary()
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": f"è·å–å¯åŠ¨çŠ¶æ€å¤±è´¥: {str(e)}",
            "system_status": {
                "is_loading": False,
                "overall_progress": 0.0,
                "is_ready": False
            }
        }

@router.post("/startup/reload")
async def force_reload():
    """å¼ºåˆ¶é‡æ–°åŠ è½½ç³»ç»Ÿ"""
    try:
        startup_manager = get_startup_manager()
        startup_manager.force_reload()
        
        return {
            "success": True,
            "message": "ç³»ç»Ÿé‡æ–°åŠ è½½å·²å¯åŠ¨",
            "status": startup_manager.get_summary()
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"å¼ºåˆ¶é‡æ–°åŠ è½½å¤±è´¥: {str(e)}"
        )

@router.get("/startup/steps")
async def get_loading_steps():
    """è·å–æ‰€æœ‰åŠ è½½æ­¥éª¤çš„ä¿¡æ¯"""
    try:
        startup_manager = get_startup_manager()
        current_status = startup_manager.get_current_status()
        
        steps = []
        for step_id, step in current_status.steps.items():
            steps.append({
                "id": step.id,
                "name": step.name,
                "description": step.description,
                "status": step.status.value,
                "progress": step.progress,
                "start_time": step.start_time.isoformat() if step.start_time else None,
                "end_time": step.end_time.isoformat() if step.end_time else None,
                "duration": step.duration,
                "error_message": step.error_message,
                "details": step.details
            })
        
        return {
            "success": True,
            "total_steps": len(steps),
            "steps": steps
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"è·å–åŠ è½½æ­¥éª¤å¤±è´¥: {str(e)}"
        )

@router.get("/document/{document_id}")
async def get_document_by_id(document_id: str, search_service: SearchService = Depends(get_search_service)):
    """æ ¹æ®IDè·å–å•ä¸ªæ–‡æ¡£"""
    try:
        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å‡†å¤‡å°±ç»ª
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail="ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•"
            )
        
        document = await search_service.get_document_by_id(document_id)
        
        if document is None:
            raise HTTPException(status_code=404, detail="æ–‡æ¡£æœªæ‰¾åˆ°")
        
        return {
            "success": True,
            "document": document
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£å¤±è´¥: {str(e)}")

@router.get("/health")
async def health_check():
    """å¢å¼ºçš„å¥åº·æ£€æŸ¥æ¥å£"""
    startup_manager = get_startup_manager()
    
    return {
        "status": "healthy" if startup_manager.is_ready() else "loading",
        "message": "æ³•æ™ºå¯¼èˆª API è¿è¡Œæ­£å¸¸",
        "ready": startup_manager.is_ready(),
        "loading": startup_manager.is_loading(),
        "startup_summary": startup_manager.get_summary()
    }

# ==================== çŸ¥è¯†å›¾è°±å¢å¼ºæœç´¢ API ====================

@router.post("/search/kg_enhanced", response_model=SearchResponse)
async def search_kg_enhanced(
    request: SearchRequest,
    search_service: SearchService = Depends(get_search_service)
):
    """çŸ¥è¯†å›¾è°±å¢å¼ºæœç´¢ - æœ€é«˜çº§çš„æœç´¢åŠŸèƒ½"""
    try:
        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å‡†å¤‡å°±ç»ª
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail="ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•"
            )

        # è°ƒç”¨çŸ¥è¯†å›¾è°±å¢å¼ºæœç´¢
        result = await search_service.search_documents_kg_enhanced(
            query_text=request.query,
            articles_count=request.articles_count,
            cases_count=request.cases_count
        )

        if not result.get('success', False):
            raise HTTPException(
                status_code=400,
                detail=result.get('error', 'çŸ¥è¯†å›¾è°±å¢å¼ºæœç´¢å¤±è´¥')
            )

        return SearchResponse(**result)

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"çŸ¥è¯†å›¾è°±å¢å¼ºæœç´¢å¤±è´¥: {str(e)}")

@router.post("/search/explain")
async def explain_search_reasoning(
    request: SearchRequest,
    search_service: SearchService = Depends(get_search_service)
):
    """è§£é‡Šæœç´¢æ¨ç†è¿‡ç¨‹"""
    try:
        # æ£€æŸ¥ç³»ç»Ÿæ˜¯å¦å‡†å¤‡å°±ç»ª
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail="ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•"
            )

        explanation = await search_service.explain_search_reasoning(request.query)

        return {
            "success": True,
            "query": request.query,
            "explanation": explanation
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æœç´¢æ¨ç†è§£é‡Šå¤±è´¥: {str(e)}")

@router.get("/knowledge_graph/stats")
async def get_knowledge_graph_stats(search_service: SearchService = Depends(get_search_service)):
    """è·å–çŸ¥è¯†å›¾è°±ç»Ÿè®¡ä¿¡æ¯"""
    try:
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail="ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•"
            )

        kg_status = search_service.get_kg_enhanced_status()

        return {
            "success": True,
            "knowledge_graph_status": kg_status
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–çŸ¥è¯†å›¾è°±çŠ¶æ€å¤±è´¥: {str(e)}")

@router.get("/knowledge_graph/relations/{entity}")
async def get_entity_relations(
    entity: str,
    entity_type: str = "auto",
    search_service: SearchService = Depends(get_search_service)
):
    """è·å–å®ä½“çš„å…³ç³»ä¿¡æ¯ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰"""
    try:
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail="ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•"
            )

        # è·å–çŸ¥è¯†å›¾è°±å®ä¾‹
        if hasattr(search_service.repository, 'data_loader'):
            knowledge_graph = search_service.repository.data_loader.get_knowledge_graph()
            if knowledge_graph:
                visualization_data = knowledge_graph.visualize_relations(entity, entity_type)
                return {
                    "success": True,
                    "entity": entity,
                    "entity_type": entity_type,
                    "visualization_data": visualization_data
                }
            else:
                raise HTTPException(status_code=404, detail="çŸ¥è¯†å›¾è°±ä¸å¯ç”¨")
        else:
            raise HTTPException(status_code=503, detail="æ•°æ®åŠ è½½å™¨ä¸å¯ç”¨")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å®ä½“å…³ç³»å¤±è´¥: {str(e)}")

@router.get("/knowledge_graph/expand/{query}")
async def expand_query_with_kg(
    query: str,
    search_service: SearchService = Depends(get_search_service)
):
    """ä½¿ç”¨çŸ¥è¯†å›¾è°±æ‰©å±•æŸ¥è¯¢"""
    try:
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail="ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•"
            )

        # è·å–çŸ¥è¯†å›¾è°±å®ä¾‹
        if hasattr(search_service.repository, 'data_loader'):
            knowledge_graph = search_service.repository.data_loader.get_knowledge_graph()
            if knowledge_graph:
                expansion_result = knowledge_graph.expand_query_with_relations(query)
                expanded_query = knowledge_graph.generate_expanded_query(query)

                return {
                    "success": True,
                    "original_query": query,
                    "expanded_query": expanded_query,
                    "expansion_details": expansion_result
                }
            else:
                raise HTTPException(status_code=404, detail="çŸ¥è¯†å›¾è°±ä¸å¯ç”¨")
        else:
            raise HTTPException(status_code=503, detail="æ•°æ®åŠ è½½å™¨ä¸å¯ç”¨")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æŸ¥è¯¢æ‰©å±•å¤±è´¥: {str(e)}")

@router.get("/knowledge_graph/crimes")
async def get_all_crimes(
    search_service: SearchService = Depends(get_search_service)
):
    """è·å–æ‰€æœ‰ç½ªååˆ—è¡¨"""
    try:
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail="ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•"
            )

        # è·å–çŸ¥è¯†å›¾è°±å®ä¾‹
        if hasattr(search_service.repository, 'data_loader'):
            knowledge_graph = search_service.repository.data_loader.get_knowledge_graph()
            if knowledge_graph:
                crimes_data = []

                # è·å–æ‰€æœ‰ç½ªååŠå…¶ç»Ÿè®¡ä¿¡æ¯
                for crime, articles in knowledge_graph.crime_article_map.items():
                    total_cases = sum(articles.values())
                    related_articles = list(articles.keys())

                    crimes_data.append({
                        "crime": crime,  # ä¿®æ”¹å­—æ®µåä»¥åŒ¹é…å‰ç«¯æœŸæœ›
                        "case_count": total_cases,
                        "related_articles": related_articles
                    })

                # æŒ‰æ¡ˆä¾‹æ•°é‡æ’åº
                crimes_data.sort(key=lambda x: x['case_count'], reverse=True)

                return {
                    "success": True,
                    "total_count": len(crimes_data),
                    "crimes": crimes_data
                }
            else:
                raise HTTPException(status_code=404, detail="çŸ¥è¯†å›¾è°±ä¸å¯ç”¨")
        else:
            raise HTTPException(status_code=503, detail="æ•°æ®åŠ è½½å™¨ä¸å¯ç”¨")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–ç½ªååˆ—è¡¨å¤±è´¥: {str(e)}")

@router.get("/knowledge_graph/articles")
async def get_all_articles(
    search_service: SearchService = Depends(get_search_service)
):
    """è·å–æ‰€æœ‰æ³•æ¡åˆ—è¡¨"""
    try:
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail="ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•"
            )

        # è·å–çŸ¥è¯†å›¾è°±å®ä¾‹
        if hasattr(search_service.repository, 'data_loader'):
            knowledge_graph = search_service.repository.data_loader.get_knowledge_graph()
            if knowledge_graph:
                articles_data = []

                # è·å–æ‰€æœ‰æ³•æ¡åŠå…¶ç»Ÿè®¡ä¿¡æ¯
                for article, crimes in knowledge_graph.article_crime_map.items():
                    total_cases = sum(crimes.values())
                    related_crimes = list(crimes.keys())

                    # éœ€è¦è·å–æ³•æ¡æ ‡é¢˜ï¼Œå…ˆç®€å•ä½¿ç”¨æ³•æ¡å·
                    articles_data.append({
                        "article_number": article,
                        "title": f"ç¬¬{article}æ¡",  # ç®€åŒ–æ ‡é¢˜ï¼Œå®é™…åº”è¯¥ä»æ•°æ®ä¸­è·å–
                        "case_count": total_cases,
                        "chapter": "åˆ‘æ³•",  # ç®€åŒ–ç« èŠ‚ä¿¡æ¯
                        "related_crimes": related_crimes
                    })

                # æŒ‰æ³•æ¡ç¼–å·æ’åº
                def sort_key(x):
                    try:
                        return int(x['article_number'])
                    except ValueError:
                        return 9999  # éæ•°å­—æ³•æ¡æ’åœ¨åé¢

                articles_data.sort(key=sort_key)

                return {
                    "success": True,
                    "total_count": len(articles_data),
                    "articles": articles_data
                }
            else:
                raise HTTPException(status_code=404, detail="çŸ¥è¯†å›¾è°±ä¸å¯ç”¨")
        else:
            raise HTTPException(status_code=503, detail="æ•°æ®åŠ è½½å™¨ä¸å¯ç”¨")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–æ³•æ¡åˆ—è¡¨å¤±è´¥: {str(e)}")

@router.get("/knowledge_graph/relation_cases/{crime}/{article}")
async def get_relation_cases(
    crime: str,
    article: str,
    limit: int = 5,
    search_service: SearchService = Depends(get_search_service)
):
    """è·å–ç‰¹å®šç½ªå-æ³•æ¡å…³ç³»çš„å…·ä½“æ¡ˆä¾‹ï¼ˆå‰Nä¸ªï¼‰"""
    try:
        startup_manager = get_startup_manager()
        if not startup_manager.is_ready():
            raise HTTPException(
                status_code=503,
                detail="ç³»ç»Ÿæ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åå†è¯•"
            )

        # è·å–çŸ¥è¯†å›¾è°±å®ä¾‹å’Œæ•°æ®åŠ è½½å™¨
        if hasattr(search_service.repository, 'data_loader'):
            data_loader = search_service.repository.data_loader
            knowledge_graph = data_loader.get_knowledge_graph()

            if knowledge_graph:
                # é¦–å…ˆä»çŸ¥è¯†å›¾è°±è·å–å…³ç³»è¯¦æƒ…
                relation_details = knowledge_graph.get_relation_details(crime, article)

                if not relation_details['exists']:
                    return {
                        "success": False,
                        "error": f"çŸ¥è¯†å›¾è°±ä¸­æ²¡æœ‰æ‰¾åˆ°'{crime}ç½ª'ä¸'ç¬¬{article}æ¡'çš„å…³ç³»",
                        "crime": crime,
                        "article": article,
                        "debug_info": {
                            "relation_exists": False,
                            "knowledge_graph_case_count": 0
                        }
                    }

                expected_case_count = relation_details['case_count']

                # æŸ¥æ‰¾ç¬¦åˆæ¡ä»¶çš„æ¡ˆä¾‹
                matching_cases = []

                # ä»æ•°æ®åŠ è½½å™¨è·å–æ¡ˆä¾‹æ•°æ®
                # ç¡®ä¿æ¡ˆä¾‹æ•°æ®å·²åŠ è½½
                if not hasattr(data_loader, 'original_data') or 'cases' not in data_loader.original_data:
                    logger.info("è§¦å‘æ¡ˆä¾‹æ•°æ®åŠ è½½...")
                    # é¦–å…ˆè°ƒç”¨æ£€æŸ¥æ–¹æ³•
                    data_loader.load_original_data()
                    # ç„¶åå¼ºåˆ¶åŠ è½½å®é™…çš„æ¡ˆä¾‹æ•°æ®åˆ°å†…å­˜
                    if not hasattr(data_loader, 'original_data'):
                        data_loader.original_data = {}
                    if 'cases' not in data_loader.original_data:
                        logger.info("å¼ºåˆ¶åŠ è½½æ¡ˆä¾‹æ•°æ®åˆ°å†…å­˜...")
                        # ä½¿ç”¨DataLoaderçš„ç§æœ‰æ–¹æ³•æ¥ä¿æŒå…¼å®¹æ€§
                        try:
                            data_loader._load_original_data_type('cases')
                        except Exception as e:
                            logger.error(f"åŠ è½½æ¡ˆä¾‹æ•°æ®å¤±è´¥: {e}")
                            data_loader.original_data['cases'] = []

                cases_data = data_loader.original_data.get('cases', [])
                if cases_data:
                    cases_found = 0

                    # æ·»åŠ è°ƒè¯•ï¼šæŸ¥çœ‹å‰å‡ ä¸ªæ¡ˆä¾‹çš„æ•°æ®æ ¼å¼
                    if len(matching_cases) == 0:  # åªåœ¨ç¬¬ä¸€æ¬¡æ‰§è¡Œæ—¶è¾“å‡º
                        logger.info(f"è°ƒè¯•ï¼šå‡†å¤‡åŒ¹é… '{crime}' ä¸ 'ç¬¬{article}æ¡'")
                        for i, case in enumerate(cases_data[:3]):
                            try:
                                case_accusations = getattr(case, 'accusations', [])
                                case_articles = getattr(case, 'relevant_articles', [])
                                logger.info(f"æ¡ˆä¾‹{i}: ç½ªå={case_accusations}, æ³•æ¡={case_articles}")
                            except Exception as e:
                                logger.error(f"æ¡ˆä¾‹{i}è§£æå¤±è´¥: {e}")

                    for case in cases_data:
                        try:
                            # è·å–æ¡ˆä¾‹çš„ç½ªåå’Œç›¸å…³æ³•æ¡
                            case_accusations = getattr(case, 'accusations', [])
                            case_articles = getattr(case, 'relevant_articles', [])

                            # ä¼˜åŒ–çš„ç½ªååŒ¹é…é€»è¾‘
                            crime_match = False
                            if case_accusations:
                                crime_normalized = crime.replace('ç½ª', '').strip()
                                for acc in case_accusations:
                                    if not acc or not isinstance(acc, str):
                                        continue
                                    acc_normalized = acc.replace('ç½ª', '').strip()
                                    # å¤šç§åŒ¹é…ç­–ç•¥
                                    if (crime == acc or  # å®Œå…¨åŒ¹é…
                                        crime_normalized == acc_normalized or  # å»"ç½ª"å­—åŒ¹é…
                                        crime in acc or acc in crime or  # åŒ…å«åŒ¹é…
                                        crime_normalized in acc_normalized or acc_normalized in crime_normalized):
                                        crime_match = True
                                        break

                            # å¢å¼ºçš„æ³•æ¡åŒ¹é…é€»è¾‘
                            article_match = False
                            if case_articles:
                                target_article_str = str(article)
                                for art in case_articles:
                                    if art is None:
                                        continue
                                    art_str = str(art).strip()
                                    # æ³•æ¡åŒ¹é…ï¼šæ”¯æŒæ•°å­—åŒ¹é…å’Œå­—ç¬¦ä¸²åŒ¹é…
                                    if (art_str == target_article_str or
                                        f"ç¬¬{art_str}æ¡" == f"ç¬¬{target_article_str}æ¡" or
                                        (art_str.isdigit() and target_article_str.isdigit() and
                                         int(art_str) == int(target_article_str))):
                                        article_match = True
                                        break

                            # å¦‚æœæ—¢åŒ¹é…ç½ªååˆåŒ¹é…æ³•æ¡ï¼Œæ·»åŠ åˆ°ç»“æœä¸­
                            if crime_match and article_match:
                                cases_found += 1
                                case_info = {
                                    "case_id": getattr(case, 'case_id', ''),
                                    "fact": getattr(case, 'fact', '')[:200] + '...' if len(getattr(case, 'fact', '')) > 200 else getattr(case, 'fact', ''),
                                    "accusations": case_accusations,
                                    "relevant_articles": case_articles,
                                    "criminals": getattr(case, 'criminals', []),
                                    "sentence_info": getattr(case, 'sentence_info', {
                                        "imprisonment_months": getattr(case, 'imprisonment_months', None),
                                        "fine_amount": getattr(case, 'fine_amount', getattr(case, 'punish_of_money', None)),
                                        "death_penalty": getattr(case, 'death_penalty', False),
                                        "life_imprisonment": getattr(case, 'life_imprisonment', False)
                                    })
                                }
                                matching_cases.append(case_info)

                                # é™åˆ¶è¿”å›æ•°é‡
                                if len(matching_cases) >= limit:
                                    break

                        except Exception as case_error:
                            # å•ä¸ªæ¡ˆä¾‹è§£æé”™è¯¯ä¸å½±å“æ•´ä½“
                            continue

                else:
                    # æ²¡æœ‰æ¡ˆä¾‹æ•°æ®çš„æƒ…å†µ
                    logger.warning(f"æ— æ³•åŠ è½½æ¡ˆä¾‹æ•°æ®ï¼Œcases_dataä¸ºç©ºã€‚æ•°æ®åŠ è½½çŠ¶æ€: {hasattr(data_loader, 'original_data')}")
                    return {
                        "success": False,
                        "error": "æ¡ˆä¾‹æ•°æ®ä¸å¯ç”¨ï¼Œæ— æ³•æŸ¥æ‰¾ç›¸å…³æ¡ˆä¾‹",
                        "crime": crime,
                        "article": article,
                        "debug_info": {
                            "knowledge_graph_case_count": expected_case_count,
                            "actual_cases_found": 0,
                            "total_cases_checked": 0,
                            "data_loader_has_original_data": hasattr(data_loader, 'original_data'),
                            "cases_in_original_data": 'cases' in data_loader.original_data if hasattr(data_loader, 'original_data') else False,
                            "error_reason": "æ¡ˆä¾‹æ•°æ®ä¸ºç©ºæˆ–åŠ è½½å¤±è´¥"
                        }
                    }

                return {
                    "success": True,
                    "crime": crime,
                    "article": article,
                    "total_found": len(matching_cases),
                    "limit": limit,
                    "cases": matching_cases,
                    "debug_info": {
                        "knowledge_graph_case_count": expected_case_count,
                        "actual_cases_found": len(matching_cases),
                        "total_cases_checked": len(cases_data),
                        "relation_confidence": relation_details['confidence'],
                        "search_params": f"Crime: '{crime}', Article: '{article}'",
                        "data_consistency": len(matching_cases) == expected_case_count
                    }
                }
            else:
                raise HTTPException(status_code=404, detail="çŸ¥è¯†å›¾è°±ä¸å¯ç”¨")
        else:
            raise HTTPException(status_code=503, detail="æ•°æ®åŠ è½½å™¨ä¸å¯ç”¨")

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–å…³ç³»æ¡ˆä¾‹å¤±è´¥: {str(e)}")

# ==================== WebSocket è·¯ç”± ====================



@router.get("/debug/modules/status")
async def get_modules_status():
    """è·å–æ¨¡å—çŠ¶æ€"""
    try:
        startup_manager = get_startup_manager()
        summary = startup_manager.get_summary()
        
        return {
            "success": True,
            "modules": {
                "data_loader": {
                    "status": "ready" if summary["is_ready"] else "loading",
                    "progress": summary["overall_progress"],
                    "current_step": summary["current_step"]
                },
                "search_engine": {
                    "status": "ready" if summary["is_ready"] else "loading"
                },
                "llm_client": {
                    "status": "ready"
                }
            },
            "system": {
                "is_ready": summary["is_ready"],
                "is_loading": summary["is_loading"],
                "overall_progress": summary["overall_progress"]
            }
        }
    except Exception as e:
        logger.error(f"è·å–æ¨¡å—çŠ¶æ€å¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e)
        }