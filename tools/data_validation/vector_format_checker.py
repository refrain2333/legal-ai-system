#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å‘é‡æ ¼å¼æ£€æŸ¥å·¥å…·
éªŒè¯å‘é‡æ•°æ®æ–‡ä»¶çš„æ ¼å¼å’Œå®Œæ•´æ€§

ä½¿ç”¨æ–¹æ³•:
python tools/data_validation/vector_format_checker.py
"""

import sys
import pickle
import numpy as np
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class VectorFormatChecker:
    """å‘é‡æ ¼å¼æ£€æŸ¥å™¨"""
    
    def __init__(self, data_root: Optional[Path] = None):
        """åˆå§‹åŒ–æ£€æŸ¥å™¨"""
        self.data_root = data_root or project_root / "data" / "processed"
        self.vectors_dir = self.data_root / "vectors"
        self.criminal_dir = self.data_root / "criminal"
        
        # é¢„æœŸé…ç½®
        self.expected_vector_dim = 768  # Lawformerå‘é‡ç»´åº¦
        self.expected_vector_dtype = np.float32
        self.required_vector_fields = ['vectors', 'metadata', 'total_count']
        
        # æ£€æŸ¥ç»“æœ
        self.results = {}
        
    def check_all_vectors(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ‰€æœ‰å‘é‡æ–‡ä»¶"""
        print("=" * 60)
        print("ğŸ” å‘é‡æ ¼å¼éªŒè¯å·¥å…· - å¼€å§‹æ£€æŸ¥")
        print("=" * 60)
        
        # æ£€æŸ¥å‘é‡ç›®å½•
        if not self.vectors_dir.exists():
            error_msg = f"å‘é‡æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.vectors_dir}"
            print(f"âŒ {error_msg}")
            return {'error': error_msg}
        
        # æ£€æŸ¥æ³•æ¡å‘é‡
        articles_file = self.vectors_dir / "criminal_articles_vectors.pkl"
        self.results['articles'] = self._check_vector_file(articles_file, "æ³•æ¡å‘é‡")
        
        # æ£€æŸ¥æ¡ˆä¾‹å‘é‡
        cases_file = self.vectors_dir / "criminal_cases_vectors.pkl"
        self.results['cases'] = self._check_vector_file(cases_file, "æ¡ˆä¾‹å‘é‡")
        
        # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
        self.results['summary'] = self._generate_summary()
        
        return self.results
    
    def _check_vector_file(self, file_path: Path, file_type: str) -> Dict[str, Any]:
        """æ£€æŸ¥å•ä¸ªå‘é‡æ–‡ä»¶"""
        print(f"\nğŸ“ æ£€æŸ¥{file_type}æ–‡ä»¶: {file_path.name}")
        
        if not file_path.exists():
            print(f"   âŒ æ–‡ä»¶ä¸å­˜åœ¨")
            return {'status': 'error', 'error': 'file_not_found'}
        
        file_size_mb = file_path.stat().st_size / (1024 * 1024)
        print(f"   ğŸ“Š æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
        
        try:
            # åŠ è½½æ•°æ®
            with open(file_path, 'rb') as f:
                data = pickle.load(f)
            
            result = {
                'status': 'success',
                'file_size_mb': file_size_mb,
                'checks': {}
            }
            
            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            result['checks']['structure'] = self._check_data_structure(data, file_type)
            
            # æ£€æŸ¥å‘é‡æ•°æ®
            if 'vectors' in data:
                result['checks']['vectors'] = self._check_vector_data(data['vectors'], file_type)
            
            # æ£€æŸ¥å…ƒæ•°æ®
            if 'metadata' in data:
                result['checks']['metadata'] = self._check_metadata(data['metadata'], file_type)
            
            # æ£€æŸ¥è®¡æ•°ä¸€è‡´æ€§
            result['checks']['count_consistency'] = self._check_count_consistency(data, file_type)
            
            return result
            
        except Exception as e:
            error_msg = f"åŠ è½½æ–‡ä»¶å¤±è´¥: {str(e)}"
            print(f"   âŒ {error_msg}")
            return {'status': 'error', 'error': error_msg}
    
    def _check_data_structure(self, data: Any, file_type: str) -> Dict[str, Any]:
        """æ£€æŸ¥æ•°æ®ç»“æ„"""
        print(f"   ğŸ”§ æ£€æŸ¥æ•°æ®ç»“æ„...")
        
        checks = {}
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå­—å…¸
        if not isinstance(data, dict):
            print(f"      âŒ æ•°æ®ä¸æ˜¯å­—å…¸æ ¼å¼")
            checks['is_dict'] = False
            return checks
        
        checks['is_dict'] = True
        print(f"      âœ… æ•°æ®ä¸ºå­—å…¸æ ¼å¼")
        
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        missing_fields = []
        for field in self.required_vector_fields:
            if field not in data:
                missing_fields.append(field)
        
        if missing_fields:
            checks['required_fields'] = False
            print(f"      âŒ ç¼ºå°‘å¿…éœ€å­—æ®µ: {missing_fields}")
        else:
            checks['required_fields'] = True
            print(f"      âœ… åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ: {self.required_vector_fields}")
        
        # æ˜¾ç¤ºå®é™…å­—æ®µ
        actual_fields = list(data.keys())
        print(f"      ğŸ“‹ å®é™…å­—æ®µ: {actual_fields}")
        checks['actual_fields'] = actual_fields
        
        return checks
    
    def _check_vector_data(self, vectors: Any, file_type: str) -> Dict[str, Any]:
        """æ£€æŸ¥å‘é‡æ•°æ®"""
        print(f"   ğŸ§® æ£€æŸ¥å‘é‡æ•°æ®...")
        
        checks = {}
        
        # æ£€æŸ¥å‘é‡ç±»å‹
        if not isinstance(vectors, np.ndarray):
            print(f"      âŒ å‘é‡ä¸æ˜¯numpyæ•°ç»„")
            checks['is_numpy_array'] = False
            return checks
        
        checks['is_numpy_array'] = True
        print(f"      âœ… å‘é‡ä¸ºnumpyæ•°ç»„")
        
        # æ£€æŸ¥å‘é‡å½¢çŠ¶
        shape = vectors.shape
        print(f"      ğŸ“ å‘é‡å½¢çŠ¶: {shape}")
        checks['shape'] = shape
        
        if len(shape) != 2:
            print(f"      âŒ å‘é‡åº”ä¸º2Dæ•°ç»„")
            checks['is_2d'] = False
        else:
            checks['is_2d'] = True
            print(f"      âœ… å‘é‡ä¸º2Dæ•°ç»„")
        
        # æ£€æŸ¥å‘é‡ç»´åº¦
        if len(shape) >= 2:
            actual_dim = shape[1]
            if actual_dim != self.expected_vector_dim:
                print(f"      âŒ å‘é‡ç»´åº¦é”™è¯¯: å®é™…{actual_dim}, é¢„æœŸ{self.expected_vector_dim}")
                checks['correct_dimension'] = False
            else:
                print(f"      âœ… å‘é‡ç»´åº¦æ­£ç¡®: {actual_dim}")
                checks['correct_dimension'] = True
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        actual_dtype = vectors.dtype
        print(f"      ğŸ”¢ æ•°æ®ç±»å‹: {actual_dtype}")
        checks['dtype'] = str(actual_dtype)
        
        if actual_dtype != self.expected_vector_dtype:
            print(f"      âš ï¸ æ•°æ®ç±»å‹éé¢„æœŸ: å®é™…{actual_dtype}, æ¨è{self.expected_vector_dtype}")
            checks['expected_dtype'] = False
        else:
            print(f"      âœ… æ•°æ®ç±»å‹æ­£ç¡®")
            checks['expected_dtype'] = True
        
        # æ£€æŸ¥å‘é‡æœ‰æ•ˆæ€§
        checks['validity'] = self._check_vector_validity(vectors)
        
        return checks
    
    def _check_vector_validity(self, vectors: np.ndarray) -> Dict[str, Any]:
        """æ£€æŸ¥å‘é‡æœ‰æ•ˆæ€§"""
        print(f"      ğŸ” æ£€æŸ¥å‘é‡æœ‰æ•ˆæ€§...")
        
        validity = {}
        
        # æ£€æŸ¥NaNå€¼
        nan_count = np.isnan(vectors).sum()
        if nan_count > 0:
            print(f"         âŒ å‘ç°{nan_count}ä¸ªNaNå€¼")
            validity['has_nan'] = True
            validity['nan_count'] = int(nan_count)
        else:
            print(f"         âœ… æ— NaNå€¼")
            validity['has_nan'] = False
        
        # æ£€æŸ¥Infå€¼
        inf_count = np.isinf(vectors).sum()
        if inf_count > 0:
            print(f"         âŒ å‘ç°{inf_count}ä¸ªInfå€¼")
            validity['has_inf'] = True
            validity['inf_count'] = int(inf_count)
        else:
            print(f"         âœ… æ— Infå€¼")
            validity['has_inf'] = False
        
        # æ£€æŸ¥é›¶å‘é‡
        zero_vectors = np.all(vectors == 0, axis=1)
        zero_count = zero_vectors.sum()
        if zero_count > 0:
            print(f"         âš ï¸ å‘ç°{zero_count}ä¸ªé›¶å‘é‡")
            validity['has_zero_vectors'] = True
            validity['zero_count'] = int(zero_count)
        else:
            print(f"         âœ… æ— é›¶å‘é‡")
            validity['has_zero_vectors'] = False
        
        # è®¡ç®—åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
        validity['stats'] = {
            'mean': float(np.mean(vectors)),
            'std': float(np.std(vectors)),
            'min': float(np.min(vectors)),
            'max': float(np.max(vectors))
        }
        
        print(f"         ğŸ“Š ç»Ÿè®¡: å‡å€¼={validity['stats']['mean']:.4f}, "
              f"æ ‡å‡†å·®={validity['stats']['std']:.4f}")
        
        return validity
    
    def _check_metadata(self, metadata: Any, file_type: str) -> Dict[str, Any]:
        """æ£€æŸ¥å…ƒæ•°æ®"""
        print(f"   ğŸ“‹ æ£€æŸ¥å…ƒæ•°æ®...")
        
        checks = {}
        
        # æ£€æŸ¥å…ƒæ•°æ®ç±»å‹
        if not isinstance(metadata, list):
            print(f"      âŒ å…ƒæ•°æ®ä¸æ˜¯åˆ—è¡¨æ ¼å¼")
            checks['is_list'] = False
            return checks
        
        checks['is_list'] = True
        print(f"      âœ… å…ƒæ•°æ®ä¸ºåˆ—è¡¨æ ¼å¼")
        
        # æ£€æŸ¥å…ƒæ•°æ®æ•°é‡
        meta_count = len(metadata)
        print(f"      ğŸ“Š å…ƒæ•°æ®æ¡ç›®æ•°é‡: {meta_count}")
        checks['count'] = meta_count
        
        if meta_count == 0:
            print(f"      âš ï¸ å…ƒæ•°æ®ä¸ºç©º")
            checks['is_empty'] = True
            return checks
        
        checks['is_empty'] = False
        
        # æ£€æŸ¥å…ƒæ•°æ®å­—æ®µ
        if metadata:
            sample_meta = metadata[0]
            if isinstance(sample_meta, dict):
                fields = list(sample_meta.keys())
                print(f"      ğŸ“‹ å…ƒæ•°æ®å­—æ®µ: {fields}")
                checks['fields'] = fields
                
                # æ ¹æ®æ–‡ä»¶ç±»å‹æ£€æŸ¥é¢„æœŸå­—æ®µ
                if file_type == "æ³•æ¡å‘é‡":
                    expected_fields = ['id', 'article_number', 'title']
                    checks['expected_fields_present'] = all(field in fields for field in expected_fields)
                elif file_type == "æ¡ˆä¾‹å‘é‡":
                    expected_fields = ['id', 'case_id', 'accusations']
                    checks['expected_fields_present'] = all(field in fields for field in expected_fields)
            else:
                print(f"      âŒ å…ƒæ•°æ®é¡¹ä¸æ˜¯å­—å…¸æ ¼å¼")
                checks['items_are_dicts'] = False
        
        return checks
    
    def _check_count_consistency(self, data: Dict[str, Any], file_type: str) -> Dict[str, Any]:
        """æ£€æŸ¥è®¡æ•°ä¸€è‡´æ€§"""
        print(f"   ğŸ”¢ æ£€æŸ¥è®¡æ•°ä¸€è‡´æ€§...")
        
        checks = {}
        
        total_count = data.get('total_count', 0)
        vector_count = len(data.get('vectors', []))
        metadata_count = len(data.get('metadata', []))
        
        print(f"      ğŸ“Š total_count: {total_count}")
        print(f"      ğŸ“Š å‘é‡æ•°é‡: {vector_count}")
        print(f"      ğŸ“Š å…ƒæ•°æ®æ•°é‡: {metadata_count}")
        
        # æ£€æŸ¥ä¸€è‡´æ€§
        counts_consistent = (total_count == vector_count == metadata_count)
        
        if counts_consistent:
            print(f"      âœ… è®¡æ•°ä¸€è‡´")
            checks['consistent'] = True
        else:
            print(f"      âŒ è®¡æ•°ä¸ä¸€è‡´")
            checks['consistent'] = False
        
        checks['total_count'] = total_count
        checks['vector_count'] = vector_count
        checks['metadata_count'] = metadata_count
        
        return checks
    
    def _generate_summary(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        print(f"\n" + "=" * 60)
        print("ğŸ“‹ éªŒè¯æ€»ç»“æŠ¥å‘Š")
        print("=" * 60)
        
        summary = {
            'timestamp': datetime.now().isoformat(),
            'total_files_checked': 0,
            'successful_files': 0,
            'failed_files': 0,
            'issues_found': [],
            'recommendations': []
        }
        
        for file_type, result in self.results.items():
            if file_type == 'summary':
                continue
            
            summary['total_files_checked'] += 1
            
            if result.get('status') == 'success':
                summary['successful_files'] += 1
                print(f"âœ… {file_type}å‘é‡æ–‡ä»¶: æ£€æŸ¥é€šè¿‡")
                
                # æ£€æŸ¥è¯¦ç»†é—®é¢˜
                issues = self._extract_issues(result, file_type)
                summary['issues_found'].extend(issues)
                
            else:
                summary['failed_files'] += 1
                print(f"âŒ {file_type}å‘é‡æ–‡ä»¶: æ£€æŸ¥å¤±è´¥ - {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                summary['issues_found'].append(f"{file_type}å‘é‡æ–‡ä»¶åŠ è½½å¤±è´¥")
        
        # ç”Ÿæˆå»ºè®®
        summary['recommendations'] = self._generate_recommendations(summary['issues_found'])
        
        print(f"\nğŸ“Š æ£€æŸ¥ç»“æœ:")
        print(f"   - æ€»æ–‡ä»¶æ•°: {summary['total_files_checked']}")
        print(f"   - æˆåŠŸ: {summary['successful_files']}")
        print(f"   - å¤±è´¥: {summary['failed_files']}")
        
        if summary['issues_found']:
            print(f"\nâš ï¸ å‘ç°çš„é—®é¢˜:")
            for issue in summary['issues_found']:
                print(f"   - {issue}")
        
        if summary['recommendations']:
            print(f"\nğŸ’¡ å»ºè®®:")
            for rec in summary['recommendations']:
                print(f"   - {rec}")
        
        if not summary['issues_found']:
            print(f"\nğŸ‰ æ‰€æœ‰å‘é‡æ•°æ®æ ¼å¼æ­£ç¡®ï¼Œå¯ä»¥æ­£å¸¸ä½¿ç”¨ï¼")
        
        return summary
    
    def _extract_issues(self, result: Dict[str, Any], file_type: str) -> List[str]:
        """æå–æ£€æŸ¥ä¸­å‘ç°çš„é—®é¢˜"""
        issues = []
        checks = result.get('checks', {})
        
        # ç»“æ„é—®é¢˜
        if not checks.get('structure', {}).get('required_fields', True):
            issues.append(f"{file_type}ç¼ºå°‘å¿…éœ€å­—æ®µ")
        
        # å‘é‡é—®é¢˜
        vector_checks = checks.get('vectors', {})
        if not vector_checks.get('is_2d', True):
            issues.append(f"{file_type}å‘é‡ä¸æ˜¯2Dæ•°ç»„")
        
        if not vector_checks.get('correct_dimension', True):
            issues.append(f"{file_type}å‘é‡ç»´åº¦ä¸æ­£ç¡®")
        
        if not vector_checks.get('expected_dtype', True):
            issues.append(f"{file_type}å‘é‡æ•°æ®ç±»å‹éæ¨èç±»å‹")
        
        validity = vector_checks.get('validity', {})
        if validity.get('has_nan', False):
            issues.append(f"{file_type}å‘é‡åŒ…å«NaNå€¼")
        
        if validity.get('has_inf', False):
            issues.append(f"{file_type}å‘é‡åŒ…å«Infå€¼")
        
        if validity.get('has_zero_vectors', False):
            issues.append(f"{file_type}åŒ…å«é›¶å‘é‡")
        
        # è®¡æ•°é—®é¢˜
        if not checks.get('count_consistency', {}).get('consistent', True):
            issues.append(f"{file_type}æ•°æ®è®¡æ•°ä¸ä¸€è‡´")
        
        return issues
    
    def _generate_recommendations(self, issues: List[str]) -> List[str]:
        """æ ¹æ®é—®é¢˜ç”Ÿæˆå»ºè®®"""
        recommendations = []
        
        if any("ç¼ºå°‘å¿…éœ€å­—æ®µ" in issue for issue in issues):
            recommendations.append("é‡æ–°ç”Ÿæˆå‘é‡æ–‡ä»¶ï¼Œç¡®ä¿åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ")
        
        if any("å‘é‡ç»´åº¦ä¸æ­£ç¡®" in issue for issue in issues):
            recommendations.append("æ£€æŸ¥Lawformeræ¨¡å‹é…ç½®ï¼Œç¡®ä¿è¾“å‡º768ç»´å‘é‡")
        
        if any("NaNå€¼" in issue or "Infå€¼" in issue for issue in issues):
            recommendations.append("æ£€æŸ¥å‘é‡ç”Ÿæˆè¿‡ç¨‹ï¼Œç¡®ä¿æ•°å€¼è®¡ç®—æ­£ç¡®")
        
        if any("é›¶å‘é‡" in issue for issue in issues):
            recommendations.append("æ£€æŸ¥è¾“å…¥æ–‡æœ¬è´¨é‡ï¼Œç¡®ä¿æ‰€æœ‰æ–‡æ¡£éƒ½æœ‰æœ‰æ„ä¹‰çš„å†…å®¹")
        
        if any("æ•°æ®è®¡æ•°ä¸ä¸€è‡´" in issue for issue in issues):
            recommendations.append("é‡æ–°ç”Ÿæˆå‘é‡æ–‡ä»¶ï¼Œç¡®ä¿å‘é‡ã€å…ƒæ•°æ®å’Œè®¡æ•°å­—æ®µåŒæ­¥")
        
        return recommendations


def main():
    """ä¸»å‡½æ•°"""
    try:
        checker = VectorFormatChecker()
        results = checker.check_all_vectors()
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
        output_file = project_root / "tools" / "data_validation" / f"vector_check_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2, default=str)
            print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_file}")
        except Exception as e:
            print(f"\nâš ï¸ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
        
        return results
        
    except Exception as e:
        print(f"âŒ éªŒè¯è¿‡ç¨‹å‡ºé”™: {e}")
        logger.exception("Vector format checking failed")
        return {'error': str(e)}


if __name__ == "__main__":
    main()