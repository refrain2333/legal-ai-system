# 核心技术逻辑深度解读 (v3)

本文件基于v2版本进行优化，旨在通过更清晰的结构和图示，深入解释云端训练套件中涉及的关键技术环节。

---

## 1. 数据提取与处理 (Data Extraction)

**目标**：将格式不一的原始文件（如Markdown、JSON）转换成程序可以轻松处理的、干净的结构化Python对象，并使用`pickle`进行持久化存储。

**核心逻辑**：通过为不同数据源编写专门的解析函数（如`process_criminal_law`），使用正则表达式等工具提取关键字段，然后将这些字段封装到自定义的类（如`LawArticle`）中，最后将这些对象列表序列化到磁盘，实现高效的“一次处理，多次使用”。

**关键代码逻辑示例 (参考 `data_pipeline/pipeline_example.py`)**：

```python
class LegalDataProcessor:
    def process_criminal_law(self, file_path):
        # 伪代码：
        # 1. 读取 markdown 文件内容
        # 2. 使用正则表达式 re.split(...) 切分篇章
        # 3. 循环处理，提取每条的标题和正文
        # 4. 创建 LawArticle 对象并存入 self.articles
        pass

    def save_to_pickle(self, output_dir):
        # with open(f"{output_dir}/articles.pkl", "wb") as f:
        #     pickle.dump(self.articles, f)
        pass
```

---

## 2. 文本向量化 (Vectorization)

**目标**：调用AI模型，将海量文本高效地转化为可用于计算的数字向量，并封装成包含元数据和统计信息的标准格式。

**核心逻辑**：将`sentence-transformers`模型封装在独立的`LawformerEmbedder`类中。通过调用其`encode`方法，可以**批量地**将文本送入GPU进行并行计算，并通过`show_progress_bar=True`参数实时显示进度。最终产出的`.pkl`文件是一个包含`vectors`、`metadata`和`statistics`等信息的字典，具备良好的自解释性。

**关键代码逻辑示例 (参考 `data_pipeline/pipeline_example.py`)**：

```python
class LawformerEmbedder:
    def encode(self, texts: list, batch_size: int = 32):
        # 伪代码：
        # return self.model.encode(texts, 
        #                          batch_size=batch_size, 
        #                          show_progress_bar=True, 
        #                          normalize_embeddings=True)
        return np.random.rand(len(texts), 768)
```

---

## 3. 模型微调 (Model Fine-tuning)

**目标**：通过对比学习，让通用模型更适应特定业务场景。

**核心逻辑 (对比学习)**：

对比学习通过“三元组（Triplet）”数据来训练模型。其核心思想可以由一个简单的图来表示：

```
      Anchor (锚点，如一个案例)
         |
         |--- 拉近 (Pull Closer) ---▶ Positive (正样本，如相关法条)
         |
         |--- 推远 (Push Away) ----▶ Negative (负样本，如无关法条)
```

这是通过**三元组损失函数 (Triplet Loss)** 实现的，其数学原理如下：

`Loss = max(0,  Distance(A, P)² - Distance(A, N)² + margin)`

这个公式的目标是让`Distance(A, P)`尽可能小，`Distance(A, N)`尽可能大，直到它们的差值超过`margin`，损失才变为0。

**关键代码逻辑示例 (参考 `model_finetuning/finetune_example.py`)**：

```python
# 1. 定义模型，包含backbone和projection_head
class LawformerContrastiveModel(torch.nn.Module):
    # ...

# 2. 定义损失函数
loss_fn = torch.nn.TripletMarginLoss(margin=0.5)

# 3. 训练循环
# for batch in dataloader:
#     optimizer.zero_grad()
#     anchor_vec, pos_vec, neg_vec = model(...)
#     loss = loss_fn(anchor_vec, pos_vec, neg_vec)
#     loss.backward()
#     optimizer.step()
```

---

## 4. 模型评估 (Model Evaluation)

**目标**：科学、量化地判断微调后的模型比基础模型好多少。

**核心逻辑**：

1.  **三元组准确率 (Triplet Accuracy)**: 
    *   **是什么**：最直观的指标。在一个三元组中，模型给出的“锚点-正样本”相似度是否**高于**“锚点-负样本”相似度。
    *   **怎么算**：`cosine_similarity(A, P) > cosine_similarity(A, N)` 是否为真。

2.  **检索召回率 (Recall@k)**: 
    *   **是什么**：模拟真实搜索。当给定一个查询（锚点）时，正确的答案（正样本）是否出现在模型返回的前`k`个结果中。
    *   **怎么算**：

    ```
    Query (锚点)
       │
       ▼
    +------------------------------------+
    |      Candidate Pool (候选文档库)      |
    +------------------------------------+
       │ (计算与库中所有文档的相似度)
       ▼
    +------------------------------------+
    |      Ranked List (排序结果)         |
    +------------------------------------+
       │ (取前k个)
       ▼
    Is the correct Positive sample in Top-k? (Y/N)
    ```

**关键代码逻辑示例 (计算Recall@k)**：

```python
# 伪代码

# 1. 计算查询与所有候选文档的相似度矩阵
similarity_matrix = np.dot(query_embeddings, candidate_embeddings.T)

for i in range(len(query_embeddings)):
    scores = similarity_matrix[i]
    
    # 2. 获取相似度最高的k个文档的索引
    top_k_indices = np.argsort(scores)[-k:]
    
    # 3. 检查正确答案的索引是否在top_k中
    if correct_answer_index in top_k_indices:
        hits += 1

recall_at_k = hits / len(query_embeddings)
```