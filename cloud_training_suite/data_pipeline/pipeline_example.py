# ç¤ºä¾‹ v2ï¼šæ•°æ®å¤„ç†ä¸å‘é‡åŒ–æµæ°´çº¿ (æ›´å…·ä½“)
# æœ¬è„šæœ¬æ›´è¯¦ç»†åœ°å±•ç¤ºäº†ä»åŸå§‹æ•°æ®åˆ°å‘é‡æ•°æ®çš„æ ¸å¿ƒå¤„ç†æµç¨‹ã€‚

import numpy as np
import re
import pickle
import time

# --- 1. å®šä¹‰æ ¸å¿ƒç±»éª¨æ¶ (å‚è€ƒ data_processor.py) ---

class LegalDataProcessor:
    """
    æ•°æ®å¤„ç†å™¨ç±»ï¼ˆéª¨æ¶ç¤ºä¾‹ï¼‰ã€‚
    è´Ÿè´£ä»åŸå§‹æ–‡ä»¶ä¸­è¯»å–ã€è§£æå’Œæ¸…æ´—æ•°æ®ã€‚
    """
    def __init__(self):
        self.articles = []
        self.cases = []
        print("  - (å·¥å…·) æ•°æ®å¤„ç†å™¨å·²åˆå§‹åŒ–ã€‚")

    def process_criminal_law(self, file_path):
        """å¤„ç†æ³•æ¡æ–‡ä»¶ (ä¼ªå®ç°)"""
        print(f"  - (å¤„ç†) æ­£åœ¨ä» {file_path} è§£ææ³•æ¡...")
        # ä¼ªä»£ç ï¼š
        # 1. è¯»å– markdown æ–‡ä»¶å†…å®¹
        # 2. ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ re.split(r"(ç¬¬[é›¶ä¸€...]+æ¡)", text) åˆ‡åˆ†ç¯‡ç« 
        # 3. å¾ªç¯å¤„ç†ï¼Œæå–æ¯æ¡çš„æ ‡é¢˜å’Œæ­£æ–‡
        # 4. åˆ›å»º LawArticle å¯¹è±¡å¹¶å­˜å…¥ self.articles
        print("  - (å¤„ç†) æ³•æ¡è§£æå®Œæˆã€‚")
        self.articles = [{"id": "law_1", "content": "æ³•æ¡å†…å®¹ç¤ºä¾‹..."}] # ç¤ºä¾‹ç»“æœ
        return self.articles

    def save_to_pickle(self, output_dir):
        """å°†å¤„ç†å¥½çš„æ•°æ®å¯¹è±¡ç”¨pickleä¿å­˜ (ä¼ªå®ç°)"""
        print(f"  - (ä¿å­˜) æ­£åœ¨å°†ç»“æ„åŒ–æ•°æ®ä¿å­˜åˆ° {output_dir}...")
        # ä¼ªä»£ç ï¼š
        # with open(f"{output_dir}/articles.pkl", "wb") as f:
        #     pickle.dump(self.articles, f)
        print("  - (ä¿å­˜) Pickleæ–‡ä»¶ä¿å­˜å®Œæˆã€‚")

# --- 2. å®šä¹‰Embedderç±»éª¨æ¶ (å‚è€ƒ lawformer_embedder.py) ---

class LawformerEmbedder:
    """
    Lawformeræ¨¡å‹å°è£…ç±»ï¼ˆéª¨æ¶ç¤ºä¾‹ï¼‰ã€‚
    è´Ÿè´£åŠ è½½æ¨¡å‹å’Œæ‰§è¡Œå‘é‡åŒ–ã€‚
    """
    def __init__(self, model_name="thunlp/Lawformer"):
        print(f"  - (å·¥å…·) æ­£åœ¨åŠ è½½AIæ¨¡å‹: {model_name}...")
        # ä¼ªä»£ç ï¼š
        # from sentence_transformers import SentenceTransformer
        # self.model = SentenceTransformer(model_name)
        print(f"  - (å·¥å…·) AIæ¨¡å‹åŠ è½½å®Œæˆã€‚")

    def encode(self, texts: list, batch_size: int = 32):
        """å°†æ–‡æœ¬åˆ—è¡¨æ‰¹é‡è½¬æ¢ä¸ºå‘é‡ (ä¼ªå®ç°)"""
        print(f"  - (å‘é‡åŒ–) å¼€å§‹å°† {len(texts)} æ®µæ–‡æœ¬æ‰¹é‡è½¬æ¢ä¸ºå‘é‡ (batch_size={batch_size})...")
        # ä¼ªä»£ç ï¼š
        # return self.model.encode(texts, batch_size=batch_size, show_progress_bar=True)
        print("  - (å‘é‡åŒ–) å‘é‡åŒ–å®Œæˆã€‚")
        return np.random.rand(len(texts), 768) # è¿”å›ä¸€ä¸ªç¬¦åˆç»´åº¦çš„éšæœºå‘é‡ä½œä¸ºç¤ºä¾‹

# --- 3. ä¸»æ‰§è¡Œå‡½æ•° ---

def run_detailed_pipeline_example():
    """
    ä¸€ä¸ªæ›´è¯¦ç»†çš„æ•°æ®å¤„ç†æµæ°´çº¿ç¤ºä¾‹å‡½æ•°ã€‚
    """
    print("ğŸš€ å¼€å§‹æ‰§è¡Œæ•°æ®å¤„ç†æµæ°´çº¿ (æ·±åŒ–ç‰ˆ)...")

    # --- æ­¥éª¤ 1: åˆå§‹åŒ–å·¥å…· ---
    print("\n[æ­¥éª¤ 1: åˆå§‹åŒ–å·¥å…·]")
    processor = LegalDataProcessor()
    embedder = LawformerEmbedder()

    # --- æ­¥éª¤ 2: å¤„ç†åŸå§‹æ–‡æœ¬æ•°æ® ---
    print("\n[æ­¥éª¤ 2: å¤„ç†åŸå§‹æ–‡æœ¬æ•°æ®]")
    processed_laws = processor.process_criminal_law("raw_data/åˆ‘æ³•.md")
    processor.save_to_pickle("processed_data/")

    # --- æ­¥éª¤ 3: æ–‡æœ¬å‘é‡åŒ– ---
    print("\n[æ­¥éª¤ 3: ä½¿ç”¨AIæ¨¡å‹è¿›è¡Œæ–‡æœ¬å‘é‡åŒ–]")
    law_contents = [item["content"] for item in processed_laws]
    law_vectors = embedder.encode(law_contents, batch_size=64)

    # --- æ­¥éª¤ 4: ä¿å­˜å‘é‡ç»“æœ ---
    print("\n[æ­¥éª¤ 4: ä¿å­˜å¤„ç†å¥½çš„å‘é‡æ•°æ®]")
    # åœ¨çœŸå®ä»£ç ä¸­ï¼Œä¼šå°†å‘é‡å’Œå…ƒæ•°æ®æ‰“åŒ…æˆä¸€ä¸ªå­—å…¸å†ä¿å­˜
    vector_package = {
        'vectors': law_vectors,
        'metadata': [{'id': item['id']} for item in processed_laws],
        'model_name': 'thunlp/Lawformer'
    }
    # with open("vectors/law_vectors.pkl", "wb") as f:
    #     pickle.dump(vector_package, f)
    print(f"  - (ä¿å­˜) å‘é‡åŒ…å·²ä¿å­˜ (åŒ…å« {law_vectors.shape[0]} ä¸ªå‘é‡)ã€‚")
    
    print("\nğŸ‰ æµæ°´çº¿ç¤ºä¾‹æ‰§è¡Œå®Œæ¯•ã€‚")

if __name__ == "__main__":
    run_detailed_pipeline_example()