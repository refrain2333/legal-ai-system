好的！既然你想学习这个技术，那我们就来实现一个**简化但完整的知识图谱系统**！学习新技术确实很有价值。

## 🎯 **学习导向的知识图谱实现方案**

我来给你设计一个**循序渐进、容易理解**的实现方案：

---

## 📚 **第一阶段：理解知识图谱基础**

### **什么是知识图谱？**
```
知识图谱 = 概念(节点) + 关系(边) + 属性

例如：
概念：合同、违约、责任、赔偿
关系：合同 --违反--> 违约 --导致--> 责任 --包含--> 赔偿
属性：合同{类型:民事, 重要性:高}, 违约{后果:严重}
```

### **在法律领域的应用**
```
用户问："房东突然要我搬走怎么办？"

传统检索：搜索"房东 搬走"
知识图谱增强：
1. 识别概念：房东→房屋租赁, 搬走→合同解除
2. 扩展查询：房屋租赁 + 合同解除 + 租客权益 + 违约责任
3. 推理路径：房屋租赁 → 合同关系 → 解除条件 → 法定程序
```

---

## 🛠️ **第二阶段：动手实现**

### **1. 创建基础结构**

```python
# 新建文件：src/knowledge_graph/__init__.py
"""
法智导航知识图谱模块
学习版本 - 重点在理解概念和实现思路
"""

__version__ = "0.1.0"
__author__ = "Legal Navigation Team"
```

### **2. 简单概念提取器**

```python
# 新建文件：src/knowledge_graph/concept_extractor.py
import jieba
import jieba.analyse
from typing import List, Dict, Tuple
import re

class LegalConceptExtractor:
    """法律概念提取器 - 学习版"""
    
    def __init__(self):
        print("初始化法律概念提取器...")
        
        # 法律专业词汇（手工整理一些，学习用）
        self.legal_terms = {
            '合同': {'type': 'legal_document', 'importance': 0.9},
            '协议': {'type': 'legal_document', 'importance': 0.9},
            '违约': {'type': 'legal_action', 'importance': 0.8},
            '责任': {'type': 'legal_consequence', 'importance': 0.8},
            '赔偿': {'type': 'legal_remedy', 'importance': 0.7},
            '租赁': {'type': 'legal_relationship', 'importance': 0.7},
            '房东': {'type': 'legal_person', 'importance': 0.6},
            '租客': {'type': 'legal_person', 'importance': 0.6},
            '解除': {'type': 'legal_action', 'importance': 0.7}
        }
        
        # 添加到jieba词典
        for term in self.legal_terms:
            jieba.add_word(term)
    
    def extract_concepts(self, text: str) -> Dict[str, Dict]:
        """从文本中提取法律概念"""
        print(f"正在提取概念：{text[:50]}...")
        
        concepts = {}
        
        # 方法1：基于预定义词典
        for term, info in self.legal_terms.items():
            if term in text:
                concepts[term] = {
                    'text': term,
                    'type': info['type'],
                    'importance': info['importance'],
                    'source': 'predefined',
                    'positions': [m.start() for m in re.finditer(term, text)]
                }
        
        # 方法2：基于TF-IDF（你已有的技术）
        try:
            keywords = jieba.analyse.extract_tags(text, topK=10, withWeight=True)
            for word, weight in keywords:
                if len(word) >= 2 and word not in concepts:  # 过滤单字，避免重复
                    concepts[word] = {
                        'text': word,
                        'type': 'extracted_concept',
                        'importance': weight,
                        'source': 'tfidf',
                        'positions': [m.start() for m in re.finditer(word, text)]
                    }
        except Exception as e:
            print(f"TF-IDF提取失败: {e}")
        
        print(f"提取到 {len(concepts)} 个概念")
        return concepts

# 测试代码
if __name__ == "__main__":
    extractor = LegalConceptExtractor()
    
    test_text = "房东违反租赁合同，要求租客提前搬走，租客可以要求赔偿损失"
    concepts = extractor.extract_concepts(test_text)
    
    print("\n提取结果：")
    for concept, info in concepts.items():
        print(f"- {concept}: {info['type']} (重要性: {info['importance']:.2f})")
```

### **3. 简单关系提取器**

```python
# 新建文件：src/knowledge_graph/relation_extractor.py
import re
from typing import List, Dict, Tuple

class LegalRelationExtractor:
    """法律关系提取器 - 学习版"""
    
    def __init__(self):
        print("初始化法律关系提取器...")
        
        # 预定义关系模式（简化版）
        self.relation_patterns = [
            # 违约关系
            {
                'pattern': r'(.+?)违反(.+?)合同',
                'relation_type': 'violates',
                'description': '违反关系'
            },
            # 导致关系  
            {
                'pattern': r'(.+?)导致(.+)',
                'relation_type': 'causes',
                'description': '因果关系'
            },
            # 要求关系
            {
                'pattern': r'(.+?)要求(.+)',
                'relation_type': 'requires',
                'description': '要求关系'
            },
            # 包含关系
            {
                'pattern': r'(.+?)包括(.+)',
                'relation_type': 'includes',
                'description': '包含关系'
            }
        ]
    
    def extract_relations(self, text: str, concepts: Dict[str, Dict]) -> List[Dict]:
        """从文本中提取概念间的关系"""
        print(f"正在提取关系：{text[:50]}...")
        
        relations = []
        concept_list = list(concepts.keys())
        
        # 方法1：基于模式匹配
        for pattern_info in self.relation_patterns:
            matches = re.finditer(pattern_info['pattern'], text)
            for match in matches:
                subject = match.group(1).strip()
                object = match.group(2).strip()
                
                # 检查是否包含已识别的概念
                subject_concept = self._find_concept_in_text(subject, concept_list)
                object_concept = self._find_concept_in_text(object, concept_list)
                
                if subject_concept and object_concept:
                    relations.append({
                        'subject': subject_concept,
                        'relation': pattern_info['relation_type'],
                        'object': object_concept,
                        'confidence': 0.8,
                        'source': 'pattern_matching',
                        'evidence': match.group(0)
                    })
        
        # 方法2：共现关系（简单但有效）
        for i, concept1 in enumerate(concept_list):
            for j, concept2 in enumerate(concept_list[i+1:], i+1):
                # 如果两个概念在文本中距离很近，认为有关系
                positions1 = concepts[concept1]['positions']
                positions2 = concepts[concept2]['positions']
                
                for pos1 in positions1:
                    for pos2 in positions2:
                        if abs(pos1 - pos2) < 50:  # 距离小于50字符
                            relations.append({
                                'subject': concept1,
                                'relation': 'co_occurs',
                                'object': concept2,
                                'confidence': 0.6,
                                'source': 'co_occurrence',
                                'distance': abs(pos1 - pos2)
                            })
                            break
        
        print(f"提取到 {len(relations)} 个关系")
        return relations
    
    def _find_concept_in_text(self, text: str, concepts: List[str]) -> str:
        """在文本中查找概念"""
        for concept in concepts:
            if concept in text:
                return concept
        return None

# 测试代码
if __name__ == "__main__":
    from concept_extractor import LegalConceptExtractor
    
    extractor = LegalConceptExtractor()
    relation_extractor = LegalRelationExtractor()
    
    test_text = "房东违反租赁合同，要求租客提前搬走，租客可以要求赔偿损失"
    
    # 先提取概念
    concepts = extractor.extract_concepts(test_text)
    print("概念：", list(concepts.keys()))
    
    # 再提取关系
    relations = relation_extractor.extract_relations(test_text, concepts)
    
    print("\n关系：")
    for rel in relations:
        print(f"- {rel['subject']} --{rel['relation']}--> {rel['object']} (置信度: {rel['confidence']})")
```

### **4. 知识图谱存储**

```python
# 新建文件：src/knowledge_graph/graph_storage.py
import networkx as nx
import pickle
import json
from typing import Dict, List, Any
from pathlib import Path

class LegalKnowledgeGraph:
    """法律知识图谱存储 - 学习版"""
    
    def __init__(self):
        print("初始化知识图谱存储...")
        self.graph = nx.DiGraph()  # 有向图
        self.concept_index = {}    # 概念索引
        self.relation_types = set()  # 关系类型集合
        
    def add_concepts(self, concepts: Dict[str, Dict]):
        """添加概念到图谱"""
        for concept_name, concept_info in concepts.items():
            self.graph.add_node(concept_name, **concept_info)
            self.concept_index[concept_name] = concept_info
        
        print(f"添加了 {len(concepts)} 个概念")
    
    def add_relations(self, relations: List[Dict]):
        """添加关系到图谱"""
        for relation in relations:
            self.graph.add_edge(
                relation['subject'],
                relation['object'],
                relation_type=relation['relation'],
                confidence=relation['confidence'],
                source=relation['source'],
                evidence=relation.get('evidence', '')
            )
            self.relation_types.add(relation['relation'])
        
        print(f"添加了 {len(relations)} 个关系")
    
    def get_related_concepts(self, concept: str, max_hops: int = 2) -> List[str]:
        """获取相关概念"""
        if concept not in self.graph:
            return []
        
        related = set()
        
        # 1跳邻居
        neighbors = list(self.graph.neighbors(concept))  # 出边
        predecessors = list(self.graph.predecessors(concept))  # 入边
        related.update(neighbors + predecessors)
        
        # 2跳邻居（如果需要）
        if max_hops >= 2:
            for neighbor in neighbors + predecessors:
                second_neighbors = list(self.graph.neighbors(neighbor))
                second_predecessors = list(self.graph.predecessors(neighbor))
                related.update(second_neighbors + second_predecessors)
        
        # 移除自己
        related.discard(concept)
        return list(related)
    
    def find_path(self, start: str, end: str) -> List[str]:
        """查找两个概念间的路径"""
        try:
            path = nx.shortest_path(self.graph, start, end)
            return path
        except nx.NetworkXNoPath:
            return []
    
    def get_concept_info(self, concept: str) -> Dict:
        """获取概念详细信息"""
        if concept not in self.graph:
            return {}
        
        node_data = self.graph.nodes[concept]
        related_concepts = self.get_related_concepts(concept)
        
        return {
            'concept': concept,
            'attributes': dict(node_data),
            'related_concepts': related_concepts,
            'in_degree': self.graph.in_degree(concept),
            'out_degree': self.graph.out_degree(concept)
        }
    
    def save_to_file(self, file_path: str):
        """保存图谱到文件"""
        graph_data = {
            'nodes': dict(self.graph.nodes(data=True)),
            'edges': list(self.graph.edges(data=True)),
            'concept_index': self.concept_index,
            'relation_types': list(self.relation_types),
            'stats': {
                'num_concepts': len(self.graph.nodes),
                'num_relations': len(self.graph.edges),
                'relation_types_count': len(self.relation_types)
            }
        }
        
        Path(file_path).parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'wb') as f:
            pickle.dump(graph_data, f)
        
        print(f"知识图谱已保存到: {file_path}")
        print(f"统计信息: {graph_data['stats']}")
    
    def load_from_file(self, file_path: str):
        """从文件加载图谱"""
        try:
            with open(file_path, 'rb') as f:
                graph_data = pickle.load(f)
            
            self.graph = nx.DiGraph()
            
            # 重建图
            for node, data in graph_data['nodes'].items():
                self.graph.add_node(node, **data)
            
            for source, target, data in graph_data['edges']:
                self.graph.add_edge(source, target, **data)
            
            self.concept_index = graph_data['concept_index']
            self.relation_types = set(graph_data['relation_types'])
            
            print(f"知识图谱已加载: {graph_data['stats']}")
            return True
            
        except Exception as e:
            print(f"加载图谱失败: {e}")
            return False

# 测试代码
if __name__ == "__main__":
    from concept_extractor import LegalConceptExtractor
    from relation_extractor import LegalRelationExtractor
    
    # 创建测试数据
    kg = LegalKnowledgeGraph()
    concept_extractor = LegalConceptExtractor()
    relation_extractor = LegalRelationExtractor()
    
    test_texts = [
        "房东违反租赁合同，要求租客提前搬走，租客可以要求赔偿损失",
        "合同当事人应当按照约定履行义务，违约方应承担违约责任",
        "租赁合同解除后，承租人应当返还租赁物"
    ]
    
    # 处理每个文本
    for text in test_texts:
        print(f"\n处理文本: {text}")
        concepts = concept_extractor.extract_concepts(text)
        relations = relation_extractor.extract_relations(text, concepts)
        
        kg.add_concepts(concepts)
        kg.add_relations(relations)
    
    # 测试查询
    print("\n=== 图谱查询测试 ===")
    print("合同的相关概念:", kg.get_related_concepts("合同"))
    print("违约的相关概念:", kg.get_related_concepts("违约"))
    print("合同到赔偿的路径:", kg.find_path("合同", "赔偿"))
    
    # 保存图谱
    kg.save_to_file("data/knowledge_graph/legal_kg.pkl")
```

---

## 🔗 **第三阶段：集成到检索系统**

### **5. 查询扩展器**

```python
# 新建文件：src/knowledge_graph/query_expander.py
from typing import List, Dict, Tuple
from .graph_storage import LegalKnowledgeGraph
from .concept_extractor import LegalConceptExtractor

class KnowledgeGraphQueryExpander:
    """基于知识图谱的查询扩展器"""
    
    def __init__(self, kg_file_path: str = "data/knowledge_graph/legal_kg.pkl"):
        print("初始化知识图谱查询扩展器...")
        self.kg = LegalKnowledgeGraph()
        self.concept_extractor = LegalConceptExtractor()
        
        # 尝试加载已有图谱
        if not self.kg.load_from_file(kg_file_path):
            print("未找到已有图谱，将使用空图谱")
    
    def expand_query(self, query: str, max_expansions: int = 5) -> Dict[str, Any]:
        """扩展用户查询"""
        print(f"扩展查询: {query}")
        
        # 1. 从查询中提取概念
        query_concepts = self.concept_extractor.extract_concepts(query)
        print(f"查询概念: {list(query_concepts.keys())}")
        
        # 2. 为每个概念找相关概念
        expansion_concepts = {}
        for concept in query_concepts:
            related = self.kg.get_related_concepts(concept, max_hops=2)
            for related_concept in related[:max_expansions]:
                if related_concept not in query_concepts:  # 避免重复
                    expansion_concepts[related_concept] = {
                        'source_concept': concept,
                        'confidence': 0.7,  # 简化的置信度
                        'type': 'kg_expansion'
                    }
        
        # 3. 构建扩展查询
        expansion_terms = list(expansion_concepts.keys())
        expanded_query = query + " " + " ".join(expansion_terms[:max_expansions])
        
        result = {
            'original_query': query,
            'expanded_query': expanded_query,
            'query_concepts': query_concepts,
            'expansion_concepts': expansion_concepts,
            'expansion_terms': expansion_terms
        }
        
        print(f"扩展结果: {expansion_terms}")
        return result

# 测试代码
if __name__ == "__main__":
    expander = KnowledgeGraphQueryExpander()
    
    test_queries = [
        "房东要我搬走",
        "合同违约怎么办",
        "租房纠纷"
    ]
    
    for query in test_queries:
        print(f"\n{'='*50}")
        result = expander.expand_query(query)
        print(f"原查询: {result['original_query']}")
        print(f"扩展查询: {result['expanded_query']}")
```

### **6. 集成到检索服务**

```python
# 修改现有的 src/services/retrieval_service.py
# 在现有类中添加知识图谱功能

class RetrievalService:
    def __init__(self, index_file: str = "data/indices/complete_semantic_index.pkl"):
        # ... 现有初始化代码 ...
        
        # 新增：知识图谱查询扩展器
        self.kg_expander = None  # 延迟初始化
    
    async def _ensure_kg_initialized(self):
        """确保知识图谱已初始化"""
        if self.kg_expander is None:
            try:
                from ..knowledge_graph.query_expander import KnowledgeGraphQueryExpander
                self.kg_expander = KnowledgeGraphQueryExpander()
                print("知识图谱查询扩展器初始化成功")
            except Exception as e:
                print(f"知识图谱初始化失败: {e}")
                self.kg_expander = False  # 标记为失败，避免重复尝试
    
    async def search(self, query: str, top_k: int = 10, 
                    enable_kg_expansion: bool = True,  # 新增参数
                    **kwargs) -> Dict[str, Any]:
        """执行检索（支持知识图谱扩展）"""
        
        search_start = time.time()
        original_query = query
        
        # 1. 知识图谱查询扩展（可选）
        kg_info = {}
        if enable_kg_expansion:
            await self._ensure_kg_initialized()
            if self.kg_expander and self.kg_expander is not False:
                try:
                    expansion_result = self.kg_expander.expand_query(query)
                    query = expansion_result['expanded_query']  # 使用扩展后的查询
                    kg_info = expansion_result
                    print(f"知识图谱扩展: {original_query} -> {query}")
                except Exception as e:
                    print(f"知识图谱扩展失败: {e}")
        
        # 2. 执行原有的检索逻辑
        if not self.is_initialized:
            await self.initialize()
            
        if not self.is_initialized:
            return {'error': 'Service initialization failed', 'results': [], 'total': 0}
        
        try:
            # 语义向量化查询（使用可能扩展后的查询）
            query_vector = await asyncio.get_event_loop().run_in_executor(
                None, self.embedding_model.encode_query, query
            )
            
            # ... 现有的检索逻辑 ...
            similarities = np.dot(self.vectors, query_vector)
            
            # 应用过滤条件
            valid_indices = np.where(similarities >= kwargs.get('min_similarity', 0.0))[0]
            
            if kwargs.get('doc_types'):
                type_mask = np.array([
                    self.metadata[i]['type'] in kwargs['doc_types'] 
                    for i in valid_indices
                ])
                valid_indices = valid_indices[type_mask]
            
            if len(valid_indices) == 0:
                return {
                    'query': original_query,
                    'expanded_query': query if enable_kg_expansion else None,
                    'results': [], 'total': 0,
                    'search_time': time.time() - search_start,
                    'message': 'No results found',
                    'kg_info': kg_info
                }
            
            # 排序并获取top-k
            valid_similarities = similarities[valid_indices]
            sorted_indices = valid_indices[np.argsort(valid_similarities)[::-1]]
            top_indices = sorted_indices[:top_k]
            
            # 构建结果
            results = []
            for idx in top_indices:
                metadata = self.metadata[idx]
                raw_similarity = float(similarities[idx])
                
                result = {
                    'id': metadata['id'],
                    'type': metadata['type'], 
                    'title': metadata['title'],
                    'score': raw_similarity,
                    'content': metadata.get('content_preview', '')[:500],
                    'similarity': raw_similarity,
                    'kg_enhanced': enable_kg_expansion and bool(kg_info)
                }
                
                if kwargs.get('include_metadata', True):
                    result['metadata'] = {
                        'source': metadata.get('source', 'unknown'),
                        'version': '0.4.1_kg_enhanced' if enable_kg_expansion else '0.4.1'
                    }
                
                results.append(result)
            
            # ... 现有的增强评分逻辑 ...
            
            search_time = time.time() - search_start
            
            return {
                'query': original_query,
                'expanded_query': query if enable_kg_expansion and query != original_query else None,
                'results': results, 
                'total': len(results),
                'search_time': search_time,
                'message': f'Found {len(results)} results' + (' with KG expansion' if kg_info else ''),
                'kg_info': kg_info if kg_info else None
            }
            
        except Exception as e:
            search_time = time.time() - search_start
            return {
                'query': original_query, 'results': [], 'total': 0,
                'error': str(e), 'search_time': search_time
            }
```

---

## 🧪 **第四阶段：测试和学习**

### **7. 创建测试脚本**

```python
# 新建文件：test_knowledge_graph.py
import asyncio
import sys
from pathlib import Path

# 添加项目路径
sys.path.insert(0, str(Path(__file__).parent))

from src.knowledge_graph.concept_extractor import LegalConceptExtractor
from src.knowledge_graph.relation_extractor import LegalRelationExtractor
from src.knowledge_graph.graph_storage import LegalKnowledgeGraph
from src.knowledge_graph.query_expander import KnowledgeGraphQueryExpander

async def test_knowledge_graph():
    """测试知识图谱功能"""
    print("🧪 开始测试知识图谱功能")
    print("="*60)
    
    # 1. 测试概念提取
    print("\n1️⃣ 测试概念提取")
    concept_extractor = LegalConceptExtractor()
    
    test_text = "房东违反租赁合同约定，单方面要求租客搬走，租客有权拒绝并要求赔偿"
    concepts = concept_extractor.extract_concepts(test_text)
    
    print(f"文本: {test_text}")
    print("提取的概念:")
    for concept, info in concepts.items():
        print(f"  - {concept}: {info['type']} (重要性: {info['importance']:.2f})")
    
    # 2. 测试关系提取
    print("\n2️⃣ 测试关系提取")
    relation_extractor = LegalRelationExtractor()
    relations = relation_extractor.extract_relations(test_text, concepts)
    
    print("提取的关系:")
    for rel in relations:
        print(f"  - {rel['subject']} --{rel['relation']}--> {rel['object']} (置信度: {rel['confidence']})")
    
    # 3. 测试图谱构建
    print("\n3️⃣ 测试图谱构建")
    kg = LegalKnowledgeGraph()
    
    # 添加多个测试文档
    test_documents = [
        "房东违反租赁合同约定，单方面要求租客搬走，租客有权拒绝并要求赔偿",
        "合同当事人应当按照约定履行义务，违约方应当承担违约责任",
        "租赁合同解除后，承租人应当返还租赁物，出租人应当退还押金",
        "当事人一方不履行合同义务的，应当承担继续履行、采取补救措施或者赔偿损失等违约责任"
    ]
    
    for doc in test_documents:
        concepts = concept_extractor.extract_concepts(doc)
        relations = relation_extractor.extract_relations(doc, concepts)
        kg.add_concepts(concepts)
        kg.add_relations(relations)
    
    # 保存图谱
    kg.save_to_file("data/knowledge_graph/test_legal_kg.pkl")
    
    # 4. 测试图谱查询
    print("\n4️⃣ 测试图谱查询")
    print("合同的相关概念:", kg.get_related_concepts("合同"))
    print("违约的相关概念:", kg.get_related_concepts("违约"))
    print("租客的相关概念:", kg.get_related_concepts("租客"))
    
    # 5. 测试查询扩展
    print("\n5️⃣ 测试查询扩展")
    expander = KnowledgeGraphQueryExpander("data/knowledge_graph/test_legal_kg.pkl")
    
    test_queries = [
        "房东要我搬走",
        "合同违约",
        "租房问题"
    ]
    
    for query in test_queries:
        result = expander.expand_query(query, max_expansions=3)
        print(f"\n查询: {result['original_query']}")
        print(f"扩展: {result['expanded_query']}")
        print(f"扩展词: {result['expansion_terms']}")
    
    # 6. 测试集成检索
    print("\n6️⃣ 测试集成检索")
    try:
        from src.services.retrieval_service import get_retrieval_service
        
        service = await get_retrieval_service()
        
        # 测试普通检索
        result1 = await service.search("合同违约", top_k=3, enable_kg_expansion=False)
        print(f"普通检索结果数: {result1['total']}")
        
        # 测试知识图谱增强检索
        result2 = await service.search("合同违约", top_k=3, enable_kg_expansion=True)
        print(f"KG增强检索结果数: {result2['total']}")
        
        if result2.get('expanded_query'):
            print(f"查询扩展: {result2['query']} -> {result2['expanded_query']}")
        
    except Exception as e:
        print(f"集成检索测试失败: {e}")
    
    print("\n✅ 知识图谱测试完成!")

if __name__ == "__main__":
    asyncio.run(test_knowledge_graph())
```

---

## 📊 **学习效果评估**

### **运行测试看效果**

```bash
# 在项目根目录运行
python test_knowledge_graph.py
```

**预期输出示例**：
```
🧪 开始测试知识图谱功能
============================================================

1️⃣ 测试概念提取
文本: 房东违反租赁合同约定，单方面要求租客搬走，租客有权拒绝并要求赔偿
提取的概念:
  - 房东: legal_person (重要性: 0.60)
  - 违反: legal_action (重要性: 0.75)
  - 租赁: legal_relationship (重要性: 0.70)
  - 合同: legal_document (重要性: 0.90)
  - 租客: legal_person (重要性: 0.60)
  - 赔偿: legal_remedy (重要性: 0.70)

2️⃣ 测试关系提取
提取的关系:
  - 房东 --violates--> 租赁 (置信度: 0.80)
  - 租客 --requires--> 赔偿 (置信度: 0.80)
  - 房东 --co_occurs--> 合同 (置信度: 0.60)

3️⃣ 测试图谱构建
添加了 15 个概念
添加了 12 个关系
知识图谱已保存到: data/knowledge_graph/test_legal_kg.pkl

4️⃣ 测试图谱查询
合同的相关概念: ['违约', '责任', '租赁', '履行']
违约的相关概念: ['合同', '责任', '赔偿']
租客的相关概念: ['房东', '租赁', '合同', '赔偿']

5️⃣ 测试查询扩展
查询: 房东要我搬走
扩展: 房东要我搬走 租赁 合同 违约
扩展词: ['租赁', '合同', '违约']

✅ 知识图谱测试完成!
```

---

## 🎓 **学习总结**

通过这个实现，你将学到：

### **1. 知识图谱的核心概念**
- 概念提取：从文本中识别实体
- 关系抽取：识别实体间的关系
- 图存储：用图结构存储知识
- 图查询：在图中查找相关信息

### **2. 实际应用技巧**
- 如何将NLP技术应用到知识图谱
- 如何设计简单但有效的关系抽取规则
- 如何将知识图谱集成到现有系统

### **3. 工程实践经验**
- 模块化设计
- 错误处理
- 性能考虑
- 测试驱动开发

### **4. 技术栈掌握**
- NetworkX图处理库
- 正则表达式模式匹配
- 异步编程集成
- 数据序列化存储

这个实现虽然简化，但包含了知识图谱的核心要素，是很好的学习项目！你想从哪个部分开始实现？
