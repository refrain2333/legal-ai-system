# 任务4：实施第四阶段 - 轻量级知识图谱增强

**目标**: 构建零成本的法律知识图谱，利用现有案例数据中的"罪名-法条"关系网络，实现智能查询扩展和关系推理，从根本上提升系统的关联查询能力。

**前置条件**:
- ✅ 混合搜索架构已完成
- ✅ LLM双引擎增强已实现
- ✅ 系统基本可以启动运行

**关联文档**: `docs/优化/法智导航_核心优化策略概览.md`

**预计用时**: 2天

**核心理念**: "零成本图谱，智能推理" - 挖掘数据中天然存在的关系网络，获得关系推理"外挂"

---

## 核心工作分解 (WBS)

### 1. 关系数据挖掘与图谱构建 (1天)

#### 任务1.1: 罪名-法条关系抽取
- [ ] **创建文件**: `src/infrastructure/knowledge/relation_extractor.py`
- **核心功能**:
  ```python
  class RelationExtractor:
      """从现有案例数据中抽取罪名-法条关系"""

      def __init__(self, data_loader):
          self.data_loader = data_loader
          self.crime_article_mapping = {}  # 罪名->法条列表
          self.article_crime_mapping = {}  # 法条->罪名列表

      def extract_relations_from_cases(self) -> Dict[str, Any]:
          """从17,131个案例中抽取关系"""
          cases_data = self.data_loader.get_all_cases()

          for case in cases_data:
              accusations = case.get('accusations', [])  # 罪名列表
              relevant_articles = case.get('relevant_articles', [])  # 相关法条

              # 构建双向映射关系
              for crime in accusations:
                  crime = self._normalize_crime_name(crime)
                  for article in relevant_articles:
                      article_num = self._extract_article_number(article)

                      # 罪名->法条映射
                      if crime not in self.crime_article_mapping:
                          self.crime_article_mapping[crime] = {}
                      if article_num not in self.crime_article_mapping[crime]:
                          self.crime_article_mapping[crime][article_num] = 0
                      self.crime_article_mapping[crime][article_num] += 1

                      # 法条->罪名映射
                      if article_num not in self.article_crime_mapping:
                          self.article_crime_mapping[article_num] = {}
                      if crime not in self.article_crime_mapping[article_num]:
                          self.article_crime_mapping[article_num][crime] = 0
                      self.article_crime_mapping[article_num][crime] += 1

          return self._generate_statistics()

      def _normalize_crime_name(self, crime: str) -> str:
          """标准化罪名"""
          # 移除"罪"后缀，统一格式
          return crime.replace('罪', '').strip()

      def _extract_article_number(self, article: str) -> str:
          """提取法条编号"""
          import re
          match = re.search(r'第?(\d+)条', article)
          return match.group(1) if match else article

      def _generate_statistics(self) -> Dict[str, Any]:
          """生成关系统计信息"""
          return {
              'total_crimes': len(self.crime_article_mapping),
              'total_articles': len(self.article_crime_mapping),
              'total_relations': sum(len(articles) for articles in self.crime_article_mapping.values()),
              'crime_article_mapping': self.crime_article_mapping,
              'article_crime_mapping': self.article_crime_mapping
          }
  ```

#### 任务1.2: 轻量级知识图谱构建
- [ ] **创建文件**: `src/infrastructure/knowledge/legal_knowledge_graph.py`
- **图谱实现**:
  ```python
  class LegalKnowledgeGraph:
      """轻量级法律知识图谱"""

      def __init__(self, relation_data: Dict):
          self.crime_article_map = relation_data['crime_article_mapping']
          self.article_crime_map = relation_data['article_crime_mapping']
          self.confidence_threshold = 0.1  # 关系置信度阈值

      def get_related_articles(self, crime: str, top_k: int = 5) -> List[Dict]:
          """根据罪名获取相关法条"""
          crime_normalized = self._normalize_input(crime)

          if crime_normalized in self.crime_article_map:
              articles = self.crime_article_map[crime_normalized]
              # 按关联频次排序
              sorted_articles = sorted(articles.items(), key=lambda x: x[1], reverse=True)

              results = []
              total_cases = sum(articles.values())

              for article_num, count in sorted_articles[:top_k]:
                  confidence = count / total_cases
                  if confidence >= self.confidence_threshold:
                      results.append({
                          'article_number': article_num,
                          'confidence': confidence,
                          'case_count': count,
                          'relation_type': 'crime_to_article'
                      })
              return results
          return []

      def get_related_crimes(self, article_num: str, top_k: int = 5) -> List[Dict]:
          """根据法条获取相关罪名"""
          article_normalized = str(article_num).replace('第', '').replace('条', '')

          if article_normalized in self.article_crime_map:
              crimes = self.article_crime_map[article_normalized]
              sorted_crimes = sorted(crimes.items(), key=lambda x: x[1], reverse=True)

              results = []
              total_cases = sum(crimes.values())

              for crime, count in sorted_crimes[:top_k]:
                  confidence = count / total_cases
                  if confidence >= self.confidence_threshold:
                      results.append({
                          'crime_name': crime + '罪',
                          'confidence': confidence,
                          'case_count': count,
                          'relation_type': 'article_to_crime'
                      })
              return results
          return []

      def expand_query_with_relations(self, query: str) -> Dict[str, Any]:
          """基于知识图谱扩展查询"""
          expansion_results = {
              'original_query': query,
              'related_articles': [],
              'related_crimes': [],
              'expansion_strategies': []
          }

          # 检测查询中的罪名
          detected_crimes = self._detect_crimes_in_query(query)
          for crime in detected_crimes:
              related_articles = self.get_related_articles(crime)
              expansion_results['related_articles'].extend(related_articles)
              if related_articles:
                  expansion_results['expansion_strategies'].append(f'detected_crime:{crime}')

          # 检测查询中的法条
          detected_articles = self._detect_articles_in_query(query)
          for article in detected_articles:
              related_crimes = self.get_related_crimes(article)
              expansion_results['related_crimes'].extend(related_crimes)
              if related_crimes:
                  expansion_results['expansion_strategies'].append(f'detected_article:{article}')

          return expansion_results

      def _detect_crimes_in_query(self, query: str) -> List[str]:
          """检测查询中的罪名"""
          detected = []
          for crime in self.crime_article_map.keys():
              if crime in query or f'{crime}罪' in query:
                  detected.append(crime)
          return detected

      def _detect_articles_in_query(self, query: str) -> List[str]:
          """检测查询中的法条编号"""
          import re
          article_patterns = [
              r'第?(\d+)条',
              r'(\d+)条',
              r'第(\d+)',
          ]

          detected = []
          for pattern in article_patterns:
              matches = re.findall(pattern, query)
              detected.extend(matches)

          return list(set(detected))  # 去重

      def _normalize_input(self, text: str) -> str:
          """标准化输入文本"""
          return text.replace('罪', '').strip()
  ```

#### 任务1.3: 图谱数据持久化
- [ ] **创建文件**: `src/infrastructure/knowledge/graph_storage.py`
- **存储管理**:
  ```python
  class GraphStorage:
      """知识图谱存储管理"""

      def __init__(self, storage_path: str = "./data/processed/knowledge_graph.pkl"):
          self.storage_path = Path(storage_path)

      def save_graph_data(self, relation_data: Dict):
          """保存图谱数据"""
          with open(self.storage_path, 'wb') as f:
              pickle.dump(relation_data, f)
          logger.info(f"知识图谱数据已保存到: {self.storage_path}")

      def load_graph_data(self) -> Optional[Dict]:
          """加载图谱数据"""
          if self.storage_path.exists():
              with open(self.storage_path, 'rb') as f:
                  return pickle.load(f)
          return None

      def is_graph_available(self) -> bool:
          """检查图谱是否可用"""
          return self.storage_path.exists()
  ```

### 2. 图谱增强搜索集成 (1天)

#### 任务2.1: 图谱增强的搜索引擎
- [ ] **创建文件**: `src/infrastructure/search/knowledge_enhanced_engine.py`
- **增强搜索实现**:
  ```python
  class KnowledgeEnhancedSearchEngine:
      """知识图谱增强的搜索引擎"""

      def __init__(self, multi_retrieval_engine, knowledge_graph):
          self.multi_retrieval_engine = multi_retrieval_engine
          self.knowledge_graph = knowledge_graph

      async def knowledge_enhanced_search(self, query: str, top_k: int = 20) -> List[Dict]:
          """知识图谱增强搜索"""
          start_time = time.time()

          try:
              # 1. 基于知识图谱扩展查询
              query_expansion = self.knowledge_graph.expand_query_with_relations(query)

              # 2. 构建扩展搜索策略
              search_results = {}

              # 原始查询搜索
              original_results = await self.multi_retrieval_engine.three_way_retrieval(query, top_k)
              self._merge_results_with_weight(search_results, original_results, weight=0.5, source="original")

              # 基于相关法条的搜索
              for article_info in query_expansion['related_articles']:
                  article_query = f"第{article_info['article_number']}条"
                  article_results = await self.multi_retrieval_engine.three_way_retrieval(article_query, top_k // 2)
                  weight = 0.3 * article_info['confidence']  # 根据置信度调整权重
                  self._merge_results_with_weight(search_results, article_results, weight=weight, source="related_article")

              # 基于相关罪名的搜索
              for crime_info in query_expansion['related_crimes']:
                  crime_query = crime_info['crime_name']
                  crime_results = await self.multi_retrieval_engine.three_way_retrieval(crime_query, top_k // 2)
                  weight = 0.2 * crime_info['confidence']
                  self._merge_results_with_weight(search_results, crime_results, weight=weight, source="related_crime")

              # 3. 最终排序和去重
              final_results = self._final_ranking_with_diversity(search_results, top_k)

              # 4. 添加图谱元信息
              for result in final_results:
                  result['knowledge_expansion'] = query_expansion
                  result['kg_enhanced'] = True

              duration = time.time() - start_time
              logger.info(f"知识图谱增强搜索完成: {len(final_results)}个结果，耗时{duration:.2f}s")

              return final_results

          except Exception as e:
              logger.error(f"知识图谱增强搜索失败: {e}")
              # 降级到原始三路召回
              return await self.multi_retrieval_engine.three_way_retrieval(query, top_k)

      def _merge_results_with_weight(self, results_dict: Dict, new_results: List, weight: float, source: str):
          """按权重合并搜索结果"""
          for result in new_results:
              doc_id = result['id']
              score = result.get('similarity', 0) * weight

              if doc_id in results_dict:
                  results_dict[doc_id]['total_score'] += score
                  results_dict[doc_id]['sources'].append(source)
                  results_dict[doc_id]['kg_boost'] = True
              else:
                  results_dict[doc_id] = {
                      'total_score': score,
                      'sources': [source],
                      'original_result': result,
                      'kg_boost': source != 'original'
                  }

      def _final_ranking_with_diversity(self, results_dict: Dict, top_k: int) -> List[Dict]:
          """最终排序，考虑多样性"""
          # 按总分排序
          sorted_results = sorted(
              results_dict.items(),
              key=lambda x: x[1]['total_score'],
              reverse=True
          )

          final_results = []
          article_count = 0
          case_count = 0

          for doc_id, meta in sorted_results:
              if len(final_results) >= top_k:
                  break

              result = meta['original_result'].copy()
              result['kg_total_score'] = meta['total_score']
              result['kg_sources'] = meta['sources']
              result['kg_boost'] = meta['kg_boost']

              # 保持法条和案例的平衡
              if 'article' in doc_id and article_count < top_k // 2:
                  final_results.append(result)
                  article_count += 1
              elif 'case' in doc_id and case_count < top_k // 2:
                  final_results.append(result)
                  case_count += 1
              elif len(final_results) < top_k:  # 剩余位置
                  final_results.append(result)

          return final_results
  ```

#### 任务2.2: 服务层集成
- [ ] **修改文件**: `src/services/search_service.py`
- **添加知识图谱增强搜索**:
  ```python
  async def search_documents_kg_enhanced(self, query_text: str, articles_count: int = 5,
                                       cases_count: int = 5) -> Dict[str, Any]:
      """知识图谱增强版搜索"""
      start_time = time.time()

      try:
          # 检查知识图谱是否可用
          if not hasattr(self.repository, 'kg_enhanced_engine') or not self.repository.kg_enhanced_engine:
              logger.warning("知识图谱增强引擎不可用，降级到LLM增强搜索")
              return await self.search_documents_enhanced(query_text, articles_count, cases_count)

          # 使用知识图谱增强搜索
          raw_results = await self.repository.kg_enhanced_engine.knowledge_enhanced_search(
              query_text,
              top_k=(articles_count + cases_count) * 2
          )

          # 分离结果
          articles_results = [r for r in raw_results if 'article' in r.get('id', '')][:articles_count]
          cases_results = [r for r in raw_results if 'case' in r.get('id', '')][:cases_count]

          # 转换为领域对象
          domain_articles = await self._convert_to_domain_objects(articles_results, 'article')
          domain_cases = await self._convert_to_domain_objects(cases_results, 'case')

          end_time = time.time()

          return {
              'success': True,
              'articles': domain_articles,
              'cases': domain_cases,
              'total_articles': len(domain_articles),
              'total_cases': len(domain_cases),
              'query': query_text,
              'search_context': {
                  'duration_ms': round((end_time - start_time) * 1000, 2),
                  'kg_enhanced': True,
                  'knowledge_expansion': raw_results[0].get('knowledge_expansion', {}) if raw_results else {},
                  'fusion_method': 'knowledge_graph_enhanced'
              }
          }

      except Exception as e:
          logger.error(f"知识图谱增强搜索失败: {e}")
          return await self._fallback_search_enhanced(query_text, articles_count, cases_count)
  ```

#### 任务2.3: API路由更新
- [ ] **修改文件**: `src/api/routes.py`
- **添加新的搜索端点**:
  ```python
  @router.post("/search/kg_enhanced", response_model=SearchResult)
  async def search_kg_enhanced(
      request: SearchRequest,
      search_service: SearchService = Depends(get_search_service)
  ):
      """知识图谱增强搜索"""
      try:
          result = await search_service.search_documents_kg_enhanced(
              query_text=request.query,
              articles_count=request.articles_count,
              cases_count=request.cases_count
          )
          return SearchResult(**result)
      except Exception as e:
          raise HTTPException(status_code=500, detail=f"搜索失败: {str(e)}")
  ```

### 3. 系统集成与配置 (0.5天)

#### 任务3.1: 图谱初始化集成
- [ ] **修改文件**: `src/infrastructure/storage/data_loader.py`
- **集成图谱构建**:
  ```python
  def load_all(self) -> Dict[str, Any]:
      """加载所有数据（包括知识图谱构建）"""
      # ... 现有加载逻辑

      # 构建知识图谱
      kg_stats = self._build_knowledge_graph()

      stats['knowledge_graph'] = kg_stats
      return stats

  def _build_knowledge_graph(self) -> Dict[str, Any]:
      """构建知识图谱"""
      try:
          from ..knowledge.relation_extractor import RelationExtractor
          from ..knowledge.graph_storage import GraphStorage

          storage = GraphStorage()

          # 检查是否已有图谱数据
          if storage.is_graph_available():
              logger.info("知识图谱数据已存在，跳过构建")
              return {'status': 'loaded_from_cache'}

          # 构建新的图谱
          logger.info("开始构建知识图谱...")
          extractor = RelationExtractor(self)
          relation_data = extractor.extract_relations_from_cases()

          # 保存图谱数据
          storage.save_graph_data(relation_data)

          # 创建图谱实例
          from ..knowledge.legal_knowledge_graph import LegalKnowledgeGraph
          self.knowledge_graph = LegalKnowledgeGraph(relation_data)

          return {
              'status': 'built_successfully',
              'total_crimes': relation_data['total_crimes'],
              'total_articles': relation_data['total_articles'],
              'total_relations': relation_data['total_relations']
          }

      except Exception as e:
          logger.error(f"知识图谱构建失败: {e}")
          return {'status': 'failed', 'error': str(e)}
  ```

#### 任务3.2: 配置文件更新
- [ ] **修改**: `src/config/settings.py`
  ```python
  class Settings(BaseSettings):
      # 知识图谱配置
      ENABLE_KNOWLEDGE_GRAPH: bool = True
      KG_CONFIDENCE_THRESHOLD: float = 0.1
      KG_RELATION_MIN_COUNT: int = 2
      KG_STORAGE_PATH: str = "./data/processed/knowledge_graph.pkl"

      # 知识图谱增强搜索权重
      KG_ORIGINAL_WEIGHT: float = 0.5
      KG_RELATED_ARTICLE_WEIGHT: float = 0.3
      KG_RELATED_CRIME_WEIGHT: float = 0.2
  ```

## 测试与验证

### 功能测试
- [ ] **创建**: `tests/test_knowledge_graph.py`
- **测试用例**:
  ```python
  def test_relation_extraction():
      """测试关系抽取"""
      pass

  def test_knowledge_graph_query_expansion():
      """测试查询扩展"""
      pass

  def test_kg_enhanced_search():
      """测试知识图谱增强搜索"""
      pass
  ```

### 效果验证查询
- [ ] **专项测试**:
  ```python
  kg_test_queries = [
      "盗窃罪判多少年",           # 单一罪名，应扩展相关法条
      "第264条具体内容",         # 单一法条，应扩展相关罪名
      "故意伤害和盗窃的区别",     # 多罪名比较
      "交通肇事逃逸怎么处理",     # 复合犯罪，应发现关联
      "网络诈骗案例分析"          # 现代犯罪形式
  ]
  ```

## 验收标准

### 功能验收
- [ ] 知识图谱成功从案例数据中抽取关系（202种罪名↔183个法条）
- [ ] 查询扩展功能正常，能识别查询中的罪名和法条
- [ ] 知识图谱增强搜索API正常工作
- [ ] 系统能自动构建并缓存知识图谱

### 性能验收
- [ ] 图谱构建时间 < 60秒
- [ ] 知识图谱增强搜索响应时间 < 500ms
- [ ] 查询扩展准确率 > 80%
- [ ] 综合评估得分提升 > 10%

### 质量验收
- [ ] 关系抽取准确性验证
- [ ] 多样化搜索结果验证
- [ ] 降级机制有效性验证

## 预期成果

### 🎯 性能提升目标
- **综合得分**: 当前基线 → **55%+** (+10%以上)
- **关联查询能力**: 获得关系推理"外挂"
- **查询理解**: 自动识别并扩展相关概念

### 💡 核心优势
1. **零额外成本**: 完全基于现有数据构建
2. **自动更新**: 数据更新时图谱自动重建
3. **轻量实现**: 简单字典结构，无需复杂图数据库
4. **即时生效**: 立即获得关系推理能力

### 🚀 突破性功能
- **智能关联**: 用户查询"盗窃罪"时自动关联第264条
- **反向推理**: 查询"第264条"时自动关联盗窃罪案例
- **隐藏发现**: 发现用户未明确提及的相关法条和罪名
- **置信度量化**: 基于案例频次提供关系置信度

**成功标志**: 当用户查询"盗窃罪的量刑标准"时，系统不仅返回盗窃罪相关结果，还能自动关联第264条、第269条等相关法条，以及入室盗窃、扒窃等相关罪名的案例，实现真正的"智能关联检索"。

---

**下一步**: 完成知识图谱后，系统将具备完整的四阶段优化能力，可选择性进入第五阶段Lawformer模型微调，追求70%+的终极性能目标。